\chapter{Background Theory}
\section{FREEDM DGI}
The FREEDM DGI is a smart grid operating system that organizes and coordinates 
power electronics and negotiates contracts to deliver power to devices and 
regions that cannot effectively facilitate their own need.

To accomplish this, the DGI software consists of a central component, the 
broker, which is responsible for presenting a communication interface and 
furnishing any common functionality needed by any algorithms used by the 
system. These algorithms are grouped into modules.

The intial work this document uses a version of the FREEDM DGI software with 
only one module: group management. Group management implements a leader
election algorithm to discover which nodes are reachable in the cyber domain.

\section{Broker Architecture}

The DGI software is designed around the broker architecture specification. Each 
core functionality of the system is implemented within a module 
which is provided access to core interfaces which deliver functionality such as 
scheduling requests, message passing, and a framework to manipulate physical 
devices, including those which exist only in simulation environments such as 
PSCAD\cite{PSCAD} and RSCAD\cite{RSCAD}.

The Broker provides a common message passing interface which all modules are 
allowed access to. This interface also provides the inter-module communication 
which delivers messages between software modules, effectively decoupling them 
outside of the requirement for them to be able to recognize messages addressed 
to them from other modules.

Several of the distributed algorithms used in the software require the use of 
ordered communication channels. To achieve this, FREEDM provides a reliable 
ordered communication protocol (The sequenced reliable connection or SRC) to 
the modules, as well as a ``best effort'' protocol (The sequenced unreliable 
connection or SUC) which is also FIFO (first in, first out), but provides 
limited delivery guarantees.

We elected to design and implement our own simple message delivery schemes in 
order to avoid complexities introduced by using TCP in our system. During 
development, it was observed that constructing a TCP connection to a node that 
had 
failed or was unreachable took a considerable amount of time. We elected to use 
UDP packets which do not have those issues, since the protocol is 
connectionless. To accomplish this lightweight protocols which are best effort 
oriented were implemented to deliver messages as quickly as possible within
the following requirements.

\subsection{Sequenced Reliable Connection.}

The sequenced reliable connection is a modified send and wait protocol with the 
ability to stop resending messages and move on to the next one in the queue if 
the message delivery time exceeds some timeout. When designing this scheme we
wanted to achieve several criteria:

\begin{itemize}
\item Messages must be accepted in order - Some distributed algorithms rely on 
the assumption that the underlying message channel is FIFO.
\item Messages can become irrelevant - Some messages may only have a short 
period in which they are worth sending. Outside of that time period, they 
should be considered inconsequential and should be skipped. To achieve this, we 
have added message expiration times. After a certain amount of time has passed, 
the sender will no longer attempt to write that message to the channel. 
Instead, he will proceed to the next unexpired message and attach a ``kill'' 
value to the message being sent, with the number of the last message the sender 
knows the receiver accepted.
\item As much effort as possible should be applied to deliver a message while 
it is still relevant.
\end{itemize}

There one adjustable parameter, the resend time, which controls how often the 
system would attempt to deliver a message it hadn't yet received an 
acknowledgment for.

To further explain the characteristics of the protocol, the psuedocode is 
included below:

\begin{algorithmic}

\State $inseqno \gets 0$
\State $outseqno \gets 1$
\State $outqueue \gets []$
\State $kill \gets null$
\State $lastack \gets 0$

\Function{Receive}{msg}
    \If {$msg.type = MSG$}
        \If {$msg.seqno = inseqno+1$}
            \State $SendAck(msg.seqno)$
            \State $inseqno \gets inseqno + 1$
        \ElsIf {$msg.seqno > inseqno$ and $msg.kill \neq null$ and $msg.kill 
\leq inseqno$}
            \State $SendAck(msg.seqno)$
            \State $inseqno \gets msg.seqno + 1$
        \Else
            \State $SendAck(inseqno)$
        \EndIf
    \ElsIf {$msg.type = ACK$}
        \If {$msg.seqno = outqueue.front.seqno$}
            \State $outqueue.pop()$
            \State $kill \gets null$
            \State $lastack \gets msg.seqno$
            \State $Write(outqueue.front,kill)$
        \Else
            \State $Write(outqueue.front,kill)$
        \EndIf
    \EndIf
\EndFunction

\Function{Send}{msg}
    \State $msg.seqno \gets outseqno$
    \State $outseqno \gets outseqno+1$
    \State $outqueue.push(msg)$
    \If {$outqueue.size = 0$}
        \State $Write(outqueue.front,kill)$
    \EndIf
\EndFunction

\Function{Resend}{}
    \While{$outqueue.size \geq 0$ and $outqueue.front.expired$}
        \State $outqueue.pop()$
        \State $kill \gets lastack$
    \EndWhile
    \If {$outqueue.size \geq 0$}
        \State $Write(outqueue.front,kill)$    
    \EndIf
\EndFunction

\end{algorithmic}

Note that the $Resend()$ function is periodically called to attempt to redeliver
lost messages to the reciever. This is, of course, a version with unbounded
sequence numbers. The implementation available with the FREEDM source code is
modified to allow for bounded sequence numbers.

\subsection{Sequenced Unreliable Connection.}

The SUC protocol is simply a best effort protocol: it employs a sliding window 
to try to deliver messages as quickly as possible. A window size is decided, 
and then at any given time, the sender can have up to that many messages in the 
channel, awaiting acknowledgment. The receiver will look for increasing 
sequence numbers, and disregard any message that is of a lower sequence number 
than is expected. The purpose of this protocol is to implement a bare minimum: 
messages are accepted in the order they are sent.

Like the SRC protocol, the SUC protocol's resend time can be adjusted. 
Additionally, the window size is also configurable, but was left unchanged for 
the tests presented in this work.

The psuedocode is included for clarity below:

\begin{algorithmic}

\State $inseqno \gets 0$
\State $outseqno \gets 0$
\State $outqueue \gets []$

\Function{Receive}{msg}
    \If {$msg.type = MSG$}
        \If {$msg.seqno > inseqno$}
            \State $SendAck(msg.seqno)$
            \State $inseqno \gets msg.seqno$
        \Else
            \State $SendAck(inseqno)$
        \EndIf
    \ElsIf {$msg.type = ACK$}
        \State $popped \gets 0$
        \If {$msg.seqno \leq outqueue.front.seqno$}
            \State $outqueue.pop()$
            \State $popped \gets popped+1$
        \EndIf
        \For{$i = WindowSize-popped \to min(WindowSize-1,outqueue.size)$}
            \State $Write(outqueue[i])$
        \EndFor
    \EndIf
\EndFunction

\Function{Send}{msg}
    \State $msg.seqno \gets outseqno$
    \State $outseqno \gets outseqno+1$
    \State $outqueue.push(msg)$
    \If {$outqueue.size \leq WindowSize$}
        \State $Write(msg)$
    \EndIf
\EndFunction

\Function{Resend}{}
    \For{$i = 0 \to min(WindowSize-1,outqueue.size)$}
        \State $Write(outqueue[i])$
    \EndFor
\EndFunction

\end{algorithmic}

\section{Group Management Algorithm}

Our software uses a leader election algorithm, ``Invitation Election 
Algorithm'' written by Garcia-Molina and listed in \cite{INVITATIONELECTION}. 
His algorithm provides a robust election procedure which allows for transient 
partitions. Transient partitions are formed when a faulty link between two or 
more clusters of DGIs causes the groups to temporarily divide. These transient 
partitions merge when the link is more reliable. The election algorithm 
allows for failures that disconnect two distinct sub-networks. These sub 
networks are fully connected, but connectivity between the two sub-networks is 
limited by an unreliable link.

\begin{algorithmic}

\State $AllNodes \gets \{ 1, 2, ..., N \}$
\State $Coordinators \gets \emptyset$
\State $UpNodes \gets { Me }$
\State $State \gets Normal$
\State $Coordinator \gets Me$
\State $Responses \gets \emptyset$
\State $Counter \gets$ A random initial identifier
\State $GroupID \gets (Me,Counter)$

\State

\Function{Check}{}
    \State This function is called periodically by the leader
    \If {$State = Normal$ and $Coordinator \gets Me$}
        \State $Responses \gets \emptyset$
        \State $TempSet \gets \emptyset$
        \For {$j = (AllNodes - \{Me\})$}
            \State $AreYouCoordinator(j)$
            \State $TempSet \gets TempSet \cup j$
        \EndFor
        \State Nodes which respond "Yes" to $AreYouCoordinator$ are put into 
the $Responses$ set. When all nodes have responded or after 
$Timeout(CheckTimeout)$, Nodes that do not respond are removed from UpNodes and 
execution continues
        \State $UpNodes \gets (TempSet-Responses) \cup {Me}$
        \If {$Responses = \emptyset$}
            \Return
        \EndIf
        \State $p \gets \max(Responses)$
        \If $Me < P$
            \State Wait time proportional to p-i
        \EndIf
        \Call{Merge}{Responses}
    \EndIf
    \State The next call to this is after Timeout(CheckTimeout)
\EndFunction

\State

\Function{Timeout}{}
    \State This function is called periodically by the group members
    \If {$Coordinator = Me$}
        \Return
    \Else
        \Call{AreYouThere}{Coordinator,GroupID,Me}
        \If{Response is No or after $Timeout(TimeoutTimeout)$}
            \Call{Recovery}{}
        \EndIf
    \EndIf
    \State The next call to this is after Timeout(TimeoutTimeout)
\EndFunction

\State

\Function{Merge}{Coordinators}
    \State This function invites all coordinators in Coordinators to join a 
group led by Me
    \State $State \gets Election$
    \State Stop work
    \State $Counter \gets Counter+1$
    \State $GroupID \gets (Me,Counter)$
    \State $Coordinator \gets Me$
    \State $TempSet \gets UpNodes - {Me}$
    \State $UpNodes \gets \emptyset$
    \For {$j \in Coordinators$}
        \Call{Invite}{j,Coordinator,GroupID}
    \EndFor
    \For {$j \in TempSet$}
        \Call{Invite}{j,Coordinator,GroupID}
    \EndFor
    \State Wait for $Timeout(InviteTimeout)$, Nodes that accept the invite are 
added to UpNodes
    \State $State \gets Reorganization$
    \For {$j \in UpNodes$}
        \Call{Ready}{j,Coordinator,GroupID,UpNodes}
    \EndFor
    \State $State \gets Normal$
\EndFunction

\State

\Function{ReceiveReady}{Sender,Leader, Identifier, Peers}
    \If {$State = Reorganization$ and $GroupID = Identifier$}
        \State $UpNodes \gets Peers$
        \State $State \gets Normal$      
    \EndIf
\EndFunction

\State

\Function{ReceiveAreYouCoordinator}{Sender}
    \If {$State = Normal$ and $Coordinator = Me$}
        \State Respond Yes
    \Else
        \State Respond No
    \EndIf
\EndFunction

\State

\Function{ReceiveAreYouThere}{Sender, Identifier}
    \If {$GroupID = Identifier$ and $Coordinator = Me$ and $Sender \in UpNodes$}
        \State Respond Yes
    \Else
        \State Respond No
    \EndIf
\EndFunction

\State

\Function{ReceiveInvitation}{Sender,Leader,Identifier}
    \If {$State \neq Normal$}
        \Return
    \EndIf
    \State Stop Work
    \State $Temp \gets Coordinator$
    \State $TempSet \gets UpNodes$
    \State $State \gets Election$
    \State $Coordinator \gets Leader$
    \State $GroupID \gets Identifier$
    \If {$Temp = Me$}
        \State Forward invite to old group members
        \For $j \in TempSet$
            \State $Invite(j,Coordinator,GroupID)$
        \EndFor
    \EndIf
    \State $Accept(Coordinator,GroupID)$
    \State $State \gets Reorganization$
    \If {$Timeout(ReadyTimeout)$ expires before $Ready$ is recieved}
        \State $Recovery()$
    \EndIf
\EndFunction

\State

\Function{ReceiveAccept}{Sender,Leader,Identifier}
    \If {$State \gets Election$ and $GroupID = Identifier$ and $Coordinator = 
Leader$}
        \State $UpNodes \gets UpNodes \cup {Sender}$
    \EndIf
\EndFunction

\State

\Function{Recovery}{}
    \State $State \gets Election$
    \State Stop Work
    \State $Counter \gets Counter + 1$
    \State $GroupID \gets (Me,Counter)$
    \State $Coordinator \gets Me$
    \State $UpNodes \gets {Me}$
    \State $State \gets Reorganization$
    \State $State \gets Normal$
\EndFunction

\end{algorithmic}


The elected leader is responsible for making work assignments and identifying 
and merging with other coordinators when they are found, as well as maintaining 
a up-to-date list of peers for the members of his group.  Likewise, members of 
the group can detect the failure of the group leader by periodically checking 
if the group leader is still alive by sending a message. If the leader fails to 
respond, the querying node will enter a recovery state and operate alone until 
they can identify another coordinator to join with. Therefore, a leader and each
of the members maintains a set of processes which are currently reachable, which
is a subset of all known processes in the system.

This Leader election can also be classified as a sort of failure detector 
(CITE).
Failure detectors are algorithms which detect the failure of processes in a 
system.
A failure detector algorithm maintains a list of processes that it suspects have
crashed. This informal description gives the failure detector strong ties to the
Leader Election process. The Group Management module maintains a list of 
suspected
processes which can be determined from the set of all processes and the current
membership. 

The leader and members have seperate roles to play in the failure detection
process. The leader, using the $Check()$ function will constantly search for 
other
leaders to join groups with. This serves as a ping / response query for 
detecting
failures in the system. It is also capable of detecting a change in state either
by network issue or crash failure that causes the process being queried to no 
longer
consider itself part of the leaders group. The member on the other hand, as the
algorithm is written will only suspect the leader, and not the other processes.
Of course, simple modifications could allow the member to suspect other members
by use of a heart beat or query-reply system, it is not implemented in DGI code.

In this work it is assumed that a leader does not span two partitoned networks:
if a group is able to form all members have some chance of communicating with
each other.


\section{Network Simulation}

Network unreliability is simulated by dropping datagrams from specific sources 
on the receiver side. Each receiver was given an XML file describing the 
Â prescribed reliability of messages arriving from a specific source. The 
network settings were loaded at run time and could be polled if necessary for 
changes in the link reliability.

On receipt of a message, the broker's communication layer examine the source 
and select randomly based on the reliability prescribed in the XML file whether 
or not to drop a message. A dropped message was not delivered to any of the 
sub-modules and was not acknowledged by the receiver. Using this method we were 
able to emulate a lossy network link but not one with message delays.

\section{System Implementation}

The FREEDM DGI software uses a Broker Architectural pattern. This design is 
realized in C++ using the Boost Library\cite{BOOST}. We have also make use of 
other languages such as Python to provide bootstrapping and start-up routines 
for the software.

\section{How the Network Reliability Simulator Fits Into the Communication 
Stack}

Because the DGI's network communication is implemented using UDP, there is a 
listener class which is responsible for accepting all incoming messages on the 
socket the system is listening on. This component is responsible for querying 
the appropriate protocol's class to determine
if a message should be accepted. To do this, when a message is received, the 
message is parsed by the listener. At this point the network simulation will 
halt processing the  message if it should be discarded based on the defined 
random chance in the configuration file. Otherwise, it is delivered to the 
addressed module.

\section{Real Time}
The DGI's specifications also call for real time reaction to events in the
system. The DGI's real-time requirements are designed to enforce a tight
upper bound on the amount of time used creating groups, discovering peers,
collecting the global state, and performing migrations.

To enforce these bounds, The real-time DGI has distinct phases which modules
are allowed to use for all processing. Each module is given a phase which
grants it a specific amount of processor time to complete any tasks it has
prepared. When the allotted time is up the scheduler changes context to the
next module. This interaction is shown in Figure \ref{fig:REALTIMESCHEDULER}

\begin{figure}[!h]
\centering
\includegraphics[width=1.0\textwidth]{RealTimeScheduler.pdf}
\captionsetup{singlelinecheck=off}
\caption[Real Time Scheduler]{The realtime scheduler uses a round robin approach to allot execution time to modules. 
\begin{enumerate}
    \item Modules request that a task be executed by specifying a time in the
          future to execute a task. A timer is set to count down to the
          specified moment. Modules may also place tasks immediately into the
          ready queue if the task may be executed immediately.
    \item When the timer expires the task is placed into the ready queue for
          the module that requested the task be executed.
    \item Modules are assigned periods of execution (called phases) which are
          a predetermined length. After the specificed amount of time has
          passed, the module's phase ends and the next module in the schedule's
          tasks begin to execute.
    \item The worker selects the next ready task for the active module from the
          ready queue and executes it. These tasks may also schedule other tasks
          to be run in the future.
\end{enumerate}
}
\label{fig:REALTIMESCHEDULER}
\end{figure}

Modules inform the scheduler of tasks it wishes to perform by either submitting
them to be performed at some point in the future, or informing the scheduler of
a tasks that is ready to be executed immediately.

Tasks that have become ready, either by being inserted as ready, or the time
period that specified when it should be executed after has passed. The prepared
task is inserted into a ready queue for the module that the task has been
scheduled for.

When that modules phase is active, the task is pulled from the ready queue and
executed. When the phase is complete, the scheduler will stop pulling tasks
from the previous modules queue and begin pulling from the next modules queue.

This allows enforcement upper bound message delay. The modules have a specific
amount of processing time allotted. Modules with messages that invoke responses
(or a series of queries and responses) typically are required to be received
within the same phase, using round numbers which enforce that the message was
sent within the same phase.

Modules are designed and allotted time to allow for parameters such as maximum
query-response time (based on the latency between communicating processes). 
This implies that a module which engages in these activities has an
upper-bound in latency before messages are considered lost.

\section{Markov Models}

Markov models are a common way of recording probabilistic processes that can
be in various states which change over time. A Markov model is a directed
graph composed of states, and transititons between these states. Each
transition has some probability attached to them.

The models begins in some initial state, and then transitions into other states
based on the probabilities assigned on each edge of the graph. Each state is
memoryless, meaning that the history of the system, or the previous states have
no effect on the next transition that occurs. Letting $Fx(s)$ equal the complete
history of a Markov chain $X$ up to time $s$, and letting $j \in S$, where $S$
is the complete set of states in the model. CITE STOICH BIO

\begin{equation}
P\{ X(t)=j | F_X(s) \} = P\{ X(t)=j | X(s) \}
\end{equation}

Additionally, the models we present are time homogenous, meaning that the
time that transition probabilties are not affected by the amount of time that
has passed in the simulation. CITE STOICH BIO

\begin{equation}
P\{ X(t)=j | X(s) \} = P\{ X(t)=j | X(0) \}
\end{equation}

Models can be either discrete time or continous time. In a discrete time model
time is divided into distinct slices. After each "slice" the system transitions
based on the random chance from each of possible transitions. The discrete model
also allows for a transition which returns to the same state.

To contrast, a continous time model assumes that the time between transitions
are exponentially distributed. Each transition has some expected value or mean
value which describes the amount of time before a transition occurs. Continous
time models do not have transitions which return to the same state since the
expected value of the transition time describes when how long the system 
remains in the same state The probability density
function (PDF) of the exponential distrobution can be written as: CITE

\begin{equation}
f(x;\lambda) = \begin{cases}
\lambda e^{-\lambda x}, & x \ge 0, \\
0, & x < 0.
\end{cases}
\end{equation}

As a result, the expected or mean value of an exponential distribution, is a function of
the parameter $\lambda$: CITE

\begin{equation}
\mathrm{E}[X] = \frac{1}{\lambda}. \!
\end{equation}

When there are multiple possible transitions from a state, each with their own
expected transition time, the expected amount of time in the state cate can be
written as:

Each transition lends to an expected amount of time expected in the state. Then,
to do a random walk of a continous time Markov chain, an intensity matrix must
also be generated in order to describe which transition is taken after the
exponentially distributed amount of time in the state has passed. Consider then
two streams of random variables, one of which is exponentially distributed and
used to determine the amount of time in a state. The second stream is normally
distributed and used to determine which state to transition to through the
intensity matrix.

To collect the in group time from a Markov model the SharpE tool was used.
Developed by Trivedi's team at Duke University, SharpE is a tool commonly used
for reliability and availibilty testing, and features a Markov chain tool. Data
collected from the simulator was used with SharpE to collect a steady state
probability (the probability that the system will be in a given state at any
given instant) from the collected simulation data.

Understanding how the dynamics of group formation is captured in a Markov Model 
is critical for both assessing its applicability and accuracy in this 
application. First, however, the dynamics of group membership must be 
understood as part of the distributed system.

Consider a set of processes, which are linked by some packet based network 
protocol. In our experiments we provide two protocols, each with different 
delivery characteristics. Under ideal conditions a packet sent by one process 
will always be delivered to its destination. Without a delivery protocol, as 
soon as packets are lost by the communication network, the message that it 
contained is lost forever. Therefore to compensate for the network losing 
packets, a large variety of delivery protocols have been adapted. Each protocol 
has a different set of goals and objectives, depending on the application.

Keeping in mind that a single lost packet does not necessitate the message it 
contained is forever lost, different protocols allow for different levels of 
reliability despite packet loss.

The leader election algorithm is centered around two critical events: checking, 
and elections. The check system is used to detect both failures and the 
availability of nodes for election.

Consider a set of processes which have already formed a group. These processes 
occasionally exchange messages to determine if the other processes have 
crashed. These processes can be classified into two sets: Leaders and Members.

When a leader sends its check messages, the nodes that receive it either 
respond in the positive, indicating that they are also leaders, or in the 
negative indicating that they have already joined a group. This message is sent 
to all known nodes in the system. If a process replies that it is also a 
leader, the original sender will enter and election mode and attempt to combine 
groups with the first process. Nodes that fail to respond are removed from the 
leaders group, if they were members.

The member on the other hand will only direct its check message to the leader 
of its current group. As with the leader's check message, the response can 
either be positive or negative. A yes response indicates that the leader is 
still available and considers the member a part of its group. A no response 
indicates that either the leader has failed and recovered, or it has suspected 
the member process of being unreachable (either due to crash or network issue) 
and has removed them from the group. In this event the member will enter a 
recovery state and reset itself to an initial configuration where it is in a 
group by itself.

On any membership change, either due to recovery, or a suspected failure, the 
list of members for a group is pushed to every member of that group by the 
leader. Members cannot suspect other processes of being crashed, only the 
leader can identify failed group members.

During elections, a highest priority leader (identified by its process id) will 
send invites to the other leaders it has identified. If those leaders accept 
the highest priority leader's invites, they will reply with an accept message 
and forward the invite to their members, if their are any. If the highest 
priority process fails to become the leader the next highest will send invites 
after a specified interval has passed.

Therefore, the membership of the system can be affected in two ways: election 
events which change the size of groups and failure suspicion (via checks) which 
decreases the size of groups. Note that elections can decrease the size of 
groups as well as increase them: If a round of forwarding invites fails by the 
new leader to his original group, the group size could decrease.

When a process is initialized it begins in the "solo" state: it is in a group 
with itself as the only member. As nodes are discovered by checks, the 
processes combine into groups. Groups are not limited by increasing one a time; 
they can increase by combined size of the groups of the leader processes.

The result is similar to a life death process with more complex skips forward 
or backward across the population.

We define a metric to assess the performance of the system under duress, we 
first consider that the distributed can only perform meaningful work when the 
processes can work together to perform physical migration. This means that 
there are two networks that affect the system's ability to do work: the 
physical and the cyber.
