\documentclass[12pt,oneside]{article}

\usepackage{comment} % multi-line comments
\usepackage{graphicx} % necessary for inclusion of .eps for figures
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[margin=1in]{geometry}
\usepackage{times}
\usepackage{setspace}
\usepackage{subcaption}
\usepackage{caption}
\usepackage{acronym}
\usepackage[T1]{fontenc}
\usepackage{float}
\doublespacing

\newtheorem{thm}{Theorem}
\newtheorem{pdef}{Definition}
\newtheorem{case}{Case}[thm]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{rem}{Remark}[thm]
\newtheorem{ill}[thm]{Illustration}

\graphicspath{ {./drawings/} {./plots/} }

\newcommand{\IEEEPARstart}[2]{#1#2}

\begin{document}

\title{MSDND: Roll for Distributed Reasoning}
\author{Stephen Jackson}
\date{March 2016}
\maketitle

\input{acronyms.tex}

\section{Introduction}

The design of stochastic models of distributed system has a long history as a challenging experience. Models of distributed systems have to deal with a number of factors. These factors include the various types of failure the system could experience, a lack of tightly synchronized execution, and a large complex state space when there are a high number of processes.  However, the concept of distributed systems plays a central role in many of the future visions for how critical infrastructure will operate in the near future. Computational systems already play a critical role in most critical infrastructures, and as demands for security features such as availability increase, distributed systems become an increasingly favorable choice for the computational needs for these systems.

The FREEDM smart-grid project follow this vision. The FREEDM center, an NSF funded ERC envisions a future power-grid where widely distributed renewable power generation and storage is closely coupled with a distributed system that facilitates the dispatch of power across an area. Other systems like VANETs and Air Traffic control also propose similar control systems where many computers must co-operate to ensure both smooth operation, and the safety of the people using the system. Because of this, ensuring the behavior of the computer systems that control these infrastructures behaves correctly during failure is critical, especially when those computer systems rely on their interaction with other computers to operate.

In a smart-grid system, misbehavior during fault conditions could lead to critical failures such as a blackout or voltage collapse. In a VANET or air traffic control system, vehicles could collide, injuring passengers or destroying property. Additionally, since these systems are a part of critical infrastructure, protecting them from malicious entities is an important consideration.

A stochastic model for a cyber-physical system is valuable while the system is being developed, but also valuable when the system is deployed in the field. [CITE] shows an application of a stochastic model in a smart-grid system being used to harden the system to protect it from message delay caused by congestion. This hardening changed the behavior of the cyber component of the CPS to allow its operation to continue (albeit with slightly different properties), while still protecting the physical system from errors that would have been caused, had the system continued without hardening for those errors.

Therefore, it is valuable for the cyber-physical system to make its own stochastic models online and make decisions about how the process should behave. However, typically, a well designed model requires an omnipotent view of the system. In distributed systems, this is particularly difficult as an instantaneous snapshot of the system is not possible without perfectly synchronous execution. Furthermore, while many algorithms for casual snapshots exist, a causal snapshot may not represent a state that the system was ever in. Additionally, taking these snapshots takes time and a model generated from that snapshot may not be viable by the time all the requisite information has been collected.

It is desirable then, to design distributed algorithms some process can infer the state of other processes and generate a stochastic model of the future from those inferences. Then, using that model the process can make decisions about how best to react to the current physical or cyber conditions that best benefits the CPS as a whole. However, the dispersal of information in a distributed system requires messages to be passed between processes, which can be disrupted by failure. The process creating the stochastic model must be able to infer the state of the other processes it is attempting to model in order to create the model.

In this work, we present a framework for reasoning about inferable state in the context of a distributed system. To do this we exploit existing work in the field of information flow security. Information flow security has been used to reason about how attacks like STUXNET can manipulate operators beliefs while disrupting the system. In particular, these approaches reason about how the operator in a STUXNET attack has no avenue to verify the reports from a compromised computing device. Using existing modal logic frameworks and using information flow security models, one can formally reason about where information that is not normally known to a domain can be inferred.

We will show in this work that in a system with the correct information flows, a process in a distributed system can infer the state of other processes in the system. With this information, that process can then construct a reasonable model of the system to determine if the current behavior could lead to an undesirable situation with either the cyber or physical network. We formalize how this flows are created using information flow security models.

Section 2 outlines the background for this work: the concepts of Modal Logic, MSDND security, Markov models and distributed algorithms. In section 3, we define how this concepts can be mapped to distributed systems and stochastic models. Section 4 defines the framework used to create information flows that allow a process to deduce the state of other processes. Section 5 has a case study of a leader election algorithm used in a smart-grid project. Finally, in section 6, we summarize our results.

\section{Background}

\subsection{Information Flow Security}

\subsubsection{Modal Logic}

Kripke frames play a critical role in the development of this work. The essential concept of this work is that each global state of the distributed system at any given instant can be captured as a countably infinite set of propositional variables. A Kripke frame is a pair <W,R> such that W is a set of of possible versions of the global state over time, where each element in W is known as a world. Each element of R describes a binary relationship for how the described system can move from world to world as events occur in the described system.

In the case of a distributed system, a world could be described as one the possible combinations of values of all boolean state variables $S=\{s_0, s_1, ... s_n\}$ in that system. As execution occurs, messages, time, or events cause these variables to change. Each change in boolean variables corresponds to a relationship in R. Therefore, a world $w$ is one possible valuation of all the variables in s and a transition from $w$ to another $w`$ (with its own valuation) can be noted as $wRw'$. Without loss of generality, each relationship in R must result in the change of at least one variable in S. Additionally, the set of world is complete: every possible combination is represented in the set of worlds. No relationship can lead to a world that does not exist.

Additionally, we can define a set of valuation functions, $\{V\}$. Each function $V^i_sx$ in $V$ describes the value observed by an entity $i$ of a boolean state variable $s_x$.  If a valuation function for a particular state variable is not defined for an entity, that entity cannot determine the value of that state variable, and cannot determine the value of any logical statement based on that variable. In the case of a distributed system, this concept is analogous to the isolation of memory for each process. For example, a process $i$, cannot simply determine the value of a variable for process $j$.

The combination of a Kripke Frame $< W,R >$ and a set of valuation functions ${V}$ is a Kripke Model model $M = \{W, R, V\}$ sometimes known as a modal model. The complete model describes all the possibilities that the modelled system can go through.

Let $\varphi \in \Phi_0$ be an atomic proposition in a set of countably many propositions. The set of well-formed formulas (wffs) as defined by the formulation rules in TABLE is the least set containing $\Phi_0$. (Operators are defined like so...). Additionally, we use the modal operator $\Box$ as an abbreviation for $\neg \Diamond \neg \varphi$. The complete axiomatic system is outlined in TABLE. For the uninitiated, the modal box operator, ``it is neccesary that'' states (in the case of $\Box \varphi$) that in every world $w$, $\varphi$ is true. As its dual, the diamond operator states, that it is not the case that in every world, $\varphi$ is true.

\begin{table*}[!t]
\centering
\begin{tabular}{r l}
1. & if $\varphi$ is a wff, so are $\neg \varphi$, $\Box \varphi$, and $\Diamond \varphi$. \\
2. & if $\varphi$ is a wff, so are $B_i \varphi$ and $\neg B_i \varphi$ \\
3. & if $\varphi$ is a wff, so are $T_{i,j} \varphi$ and $\neg T_{i,j} \varphi$ \\
4. & if $\varphi$ is a wff, so are $I_{i,j} \varphi$ and $\neg I_{i,j} \varphi$ \\
5. & if $\varphi$ and $\psi$ are both wff, so are $\varphi \wedge \psi$ \\
6. & if $\varphi$ and $\psi$ are both wff, so are $\varphi \vee \psi$ \\
\end{tabular}
\caption{Logical Statement Formulation Rules}
\label{tab:logform}
\end{table*}

\begin{table*}[!t]
\centering
Definition of logical and modal operators (abbreviations) \\
\begin{tabular}{r l}
D1. & $\varphi \wedge \psi \equiv \neg ( \neg \varphi \vee \neg \psi)$\\
D2. & $\varphi \oplus \psi \equiv (\varphi \vee \psi) \wedge \neg(\varphi \wedge \psi)$ (exclusive or)\\
D3. & $\varphi \rightarrow \psi \equiv \neg \varphi \vee \psi $\\
D4. & $\varphi \leftrightarrow \psi \equiv (\varphi \rightarrow \psi) \wedge (\psi \rightarrow \varphi)$\\
D5. & $\Diamond \psi \equiv \exists w \in W : w \vdash \varphi $\\
D6. & $\Box \varphi \equiv \neg \Diamond \neg \varphi $\\
D7. & $B_i \varphi$ Entity $i$ believes the truth of $\varphi$\\
D8. & $I_{i,j} \varphi$ Entity $j$ informs $i$ that $\varphi \equiv \top$\\
D9. & $T_{i,j} \varphi$ Entity $i$ trusts the report from $j$ about $\varphi$ \\
\end{tabular} \\~\\
Axioms \\
\begin{tabular}{r l}
P. & All the tautologies from the propositional calculus.\\
K. & $\Box (\varphi \rightarrow \psi) \rightarrow (\Box \varphi \rightarrow \Box \psi)$\\
M. & $\Box \varphi \rightarrow \varphi$\\
A1. & $\neg \Box \varphi \rightarrow \Box \neg \Box \varphi $\\
A2. & $\Diamond (\varphi \vee \psi) \rightarrow \Diamond \varphi \vee \Diamond \psi $\\
A3. & $\Box \varphi \wedge \Box \psi \rightarrow \Box (\varphi \wedge \psi)$ \\
B1. & $(B_i \varphi \wedge B_i (\varphi \rightarrow \psi )) \rightarrow B_i \psi$ \\
B2. & $\neg B_i \bot$\\
B3. & $B_i \varphi \rightarrow B_i B_i \varphi$ \\
B4. & $\neg B_i \varphi \rightarrow B_i \neg B_i \varphi$\\
I1. & $(I_{i,j} \varphi \wedge I_{i,j} (\varphi \rightarrow \psi )) \rightarrow I_{i,j} \psi$\\
I2. & $\neg I_{i,j} \bot$ \\
C1. & ($B_i I_{i,j} \varphi \wedge T_{i,j} \varphi) \rightarrow B_i \varphi$ \\
C2. & $T_{i,j} \varphi \equiv B_i T_{i,j} \varphi$ \\
\end{tabular} \\~\\
Rules of Inferrence \\
\begin{tabular}{r l}
R1. & From $\vdash \varphi$ and $\vdash \varphi \rightarrow \psi$ infer $\psi$ (Modus Ponens) \\
R2. & $\neg (\varphi \wedge \psi) \equiv (\neg \varphi \vee \neg \psi)$ (DeMorgan's)\\
R3. & From $\vdash \varphi$ infer $\vdash \Box \varphi$ (Generalization)\\
R4. & From $\vdash \varphi \equiv \psi$ infer $\vdash \Box \varphi \equiv \Box \psi$\\
R5. & From $\vdash \varphi \equiv \psi$ infer $\vdash T_{i,j} \varphi \equiv T_{i,j} \psi$\\
\end{tabular} \\
\caption{The Axiomatic System}
\label{tab:axiomaticsys}
\end{table*}

\subsubsection{Non-Deducible (MSDND) Security}

In the domain of security concepts there are a wide variety of goals worth protecting in every system. These include the core security concepts of integrity, accessibility and privacy. Most traditional security approaches rely heavily on cryptography to provide privacy. However accidental information leakage can still occur which compromises the privacy of the system. For cyber-physical systems, the leakage is difficult to control. Unlike their cyber counterparts, the actions taken by the physical components cannot be hidden from a casual observer. For example, a plane changing altitude or a car turning or changing speed cannot be hidden from an observer. Other, more complicated systems, like the power grid, have actions that are more difficult to observe, but a well motivated attacker can potentially collect critical information about the behavior of the cyber components with observations of the physical network.

Information Flow security models are invaluable for assessing what information if any is leaked by either the cyber of physical components of the CPS. There are a number of information flow security models, all based off similar concepts. Typically, these models partition the system into two domains: the high security domain and the low security domain. However, the MSDND security model allows the system to partitioned into any number of domains. The MSDND model has been used to describe how the STUXNET attack was able to hide its malicious behavior from the operators. The MSDND security model is expressed using modal logic to determine what information in a domain is deducible in a observer in another domain. MSDND security exploits the possible worlds of modal to determine if the are worlds where the value of a logical atom is deducible by someone outside the domain.

This information flow security model can be used to determine what a process in a distributed system can determine about another process. The exact specification of timing the distributed system becomes unnecessary as the modal model can express any combination of logical atoms in one of its worlds. 

The MSDND security model can be expressed as follows. Consider a pair of state variables $s_x$ and $s_y$ which may or may not be in the same security domain. The value of $s_x$ and $s_y$ have a logical xor relationship: if $s_x$ is true, $s_y$ must be false. Given an entity i that does not have a valuation function for either of those two variables, the system is MSDND secure for that entity and pair of variables. Written formally:

\begin{align}
MSDND = \exists w \in W : w \vdash \Box [ (s_x \vee s_y) \wedge \neg(s_x \wedge s_y) ] \wedge [ w \vDash ( \not \exists V_x^i (w) \wedge \not \exists V_y^i (w) ) ]
\end{align}

Of particular interest is the special case where $s_x$ and $s_y$ are relation on the same wff: $(s_x = \varphi and s_y = \neg \varphi)$:

\begin{align}
MSDND = \exists w \in W : w \vdash \Box [ \varphi \oplus \neg \varphi ] \wedge [ w \vDash ( \not \exists V_\varphi^i(w)) ]
\end{align}

In a system where the above logical relationship holds, the entity $i$ cannot determine the value of $s_x$ or $s_y$. However, if the relationship holds, there is some world where the entity can determine the value of $s_x$ and $s_y$.

\subsubsection{Belief Logic}

BIT was developed by such and such to formalize a modal logic about belief and information transfer. BIT logic has typically been applied to distributed systems, but also have played roles in CPS security. The operations of the BIT logic allow formal definition of how entities pass information, and how they will act on the information passed to them. BIT logic utilizes several modal operators:

\begin{itemize}
\item $I_{i,j} \varphi$ defines the transfer of information directly from entity $j$ to an entity $i$. 
\item $T_{i,j} \varphi$ defines trust an entity $i$ has in a report from $j$ that $\varphi$ is true.
\item $B_i \varphi$ defines the belief that an entity $i$ has about $\varphi$. The actual value of $\varphi$ is irrelevant: the entity $i$ believes it to be true.
\end{itemize}

These operators allow reasoning about information transference between entities. In the context of a distributed system, these operators allow the division of the actual state held by some entity $i$ to what some other entity $j$ believes entity $i$'s state is.

\subsection{Markov Models}

A Markov Model is a directed graph describing how a system changes over time. Each vertex of the graph is the state of the system. Each edge out of a vertex is assigned a probability, based on the probability of the system transitioning from state A to state B. A markov chain can either be continuous or discrete. In a discrete Markov chain, there is also a probability that they system remains in the same state. At each step, the system stays in the same state or transitions to the next state.

Markov chains can have many properties, which have various consequences for their behavior and how they can be analyzed. A Markov chain is a first order chain if the probability of transitioning from $i$ to $j$ does not depend on the history of transitions that lead to state $i$.
First order chains are described as having a memoryless or Markov property.
This formalizes the independence of the next state from the history of previous states.
The Markov property describes a Markov chain as a sequence of random variables $X_{1}, X_{2}, X_{3}, ...$ and states the value of $X_{n+1}$ only depends $X_{n}$: \cite{MARKOV3}

\begin{align} \Pr(X_{n+1}&=x\mid X_1=x_1, X_2=x_2, \ldots, X_n=x_n)
\nonumber \\ &= \Pr(X_{n+1}=x\mid X_n=x_n). \end{align}

An ergodic Markov chain is a chain where it is possible, in some finite number of steps, to go from any state to any other state.
A stationary Markov chain is one where the transition probabilities do not change over time.
In a stationary Markov chain, the $n$th visit to a state is indistinguishable from the $n+1$th visit to a state.

A Markov chain with $m$ states can be represented by a $m\times m$ matrix.
For simplicity when creating the model, matrices in this work are 1-indexed.
In a matrix $P$, the value of $P_{ij}$ represents the probability of the transition from $i$ to $j$.
It should be obvious the sum of each row in the matrix is equal to one:

\begin{equation} \sum_{i=1}^{m} P_{ij} = 1. \end{equation}

A useful companion to the transition matrix is a state distribution vector.
While the transition matrix describes how system will transition between states, the state distribution vector describes the probability of observing a given state.

\begin{pdef}
A state distribution vector is an $m$-dimensional vector composed of probability of observing each state in the system at a given instant:
\[ [P_{1} \quad P_{2} \quad \ldots \quad P_{m} ] \]
Where $P_{i}$ corresponds to the probability of observing state $i$.
\end{pdef}

A common, valuable analysis is the steady-state transition probability: the probability distribution that describes the likelihood of observing any particular state in a long-running system. The steady state analysis can be done on any model which is stationary and ergodic. The steady state can by found via a system of equations: \cite{MARKOV3}

\begin{align}
0\leq\pi_j\leq1.0 \\
\sum_{j = 1}^{m}\pi_j = 1.0 \\
\pi_j = \sum_{i=1}^{m} \pi_i p_{ij}
\end{align}

In the following sections, the computation of the steady state will be noted as $Steady()$.
A Markov chain can also be used to predict what state a process will be in at some point in the the future.
Given a initial state and a number of time-steps a matrix operation will yield the likelihood of the process being in each state after the time interval has passed.
The mean passage time, a measure of how many time-steps will pass before a process returns or arrives to some state, can also be calculated.

Typically construction of a Markov chain requires significant knowledge of the system being constructed. There are other approaches, such as Hidden Markov Models, where a portion of the states are hidden from the model. However, in a Hidden Markov Models, the output (depending on the hidden state) is visible to an observer. Therefore, the HMM is useful for constructing the likeliest path for a arriving at a particular observation.

Therefore, it is necessary for the purpose of constructing a model, the creator must have as much information about the system being modeled as possible in order to construct an accurate model. This poses two problems for a distributed system. First, since each process has its own set of variables, a complete naive model might necessitate a large state space (for all potential combinations of local variables). Second, order to use the model to do online analysis, complete knowledge of the changes in state variables would be needed to determine the state of the model if it was created online (if, for example, the process with the model wanted to predict what it was likely to experience in the near future.)

A good model for online analysis in a distributed system should be simple, to limit the size of the state space: complete exact knowledge of another process's state is impractical. If the model is constructible by a process it should rely on information which can be inferred by information leakage from an MSDND insecure process. Any knowledge of a processes state, inferred or otherwise by a process should have some permanence to make the model created suitable for any sort of long term analysis. The inferred information should have some lifetime (as specified in the algorithm) where the observed information is valid for some time period t.

For example, if a process A can infer some state for Process B, the state that A infers about B will remain the state of B for an amount of time sufficient for whatever predictive needs A uses the inferred information for. Of course, if Process B crashes, and the value was stored in volatile memory then the information inferred by A is no longer correct. Therefore, crash failures are largely ignored in this work. However, some of the later analysis for omission failures can be applied to crash failures that happen predictably (ie, a process always crashes at a particular point in the algorithm).

\section{Methods}

A model created of a distributed system must have sufficient information to create an accurate model. This information is difficult to obtain because of the circumstances many distributed systems run on. Without exact synchronization, an accurate global snapshot of the system cannot be taken. Instead of attempting to capture exact global snapshots, our approach relies on allowing a process to reason about the state of the other processes in the system in order to allow that process to construct a model which can then be distributed to other processes.

To do this we propose the following structure for the execution environment of the distributed system:
Each process has some set logical atoms which it manipulates as its algorithms execute.
Each process belongs to domain unique to that process (process $i$ is the only member of logical domain $D_i$)
No process can directly access a logical axiom outside of its domain.
The authenticity of any information transfer (Using modal operator $I_{i,j}$) is never not trusted. However, the Trust ($T_{i,j}$) operator is still used to describe a message that is lost in transit: in all logical formulas presented the Trust operator describes this circumstance.
Processes do not exhibit Byzantine failure, nor do they crash, only messages may be omitted.

\subsection{Centralizing Certainty}


If no information is passed between processes, they are MSDND secure (ignoring any sort of leakage from interactions in the physical world). As information is passed, aspects of the processes state are leaked. However, depending on when messages are sent, the process can be left in doubt as to the state of the other process. This has a common analogy to the two armies problem. 

\subsubsection{Two Armies Problem}

In the two armies problem, the each of the generals of the armies must agree on what time to attack the enemy city. If the generals do not make an agreement on the attack, the attack will fail. However, the generals must come to an agreement when their channel for communication (a messenger) is unreliable (they can be captured by the enemy). After one message has been sent, to one of the two generals, state of the other is MSDND secure. Let $\varphi_0$ be a logical atom that indicates ``General A will attack at dawn.'' For simplicity, we assume that after the time to attack is decided by General A, the processes will not reconsider the plan.

\begin{thm}
If no messages are exchanged, the state of the two generals is mutually MSDND secure. \label{thm:nomsg}
\end{thm}

Proof: If no messages are exchanged and no information is leaked from the physical world, the two generals have no way of determining the other's state.

\begin{thm}
Once at least one messenger delivers a message to one of the Generals, one of the generals is not MSDND secure.
\end{thm}

Proof:
Let $\{ \varphi_i : i \in 1,2 ... n \}$ describe the state that a general has received $\varphi_{i-1}$.

\begin{case}
One messenger is sent by General A and arrives at General B.
\label{case:generalsn0}
\end{case}

If no confirmations are sent, then General A clearly cannot deduce if General B has received the message and to General A, then to A, B is MSDND secure because it has no way to valuate $B_B \varphi_0$. However, to B, if B believes A's message then A is not MSDND secure to B, because B believes that $\varphi_0$ is true.

\newpage

\begin{table*}[h!]
\centering
\begin{tabular}{r r l}
1. & $\varphi_0$ & General A decides to attack at dawn. \\
2. & $I_{B,A} \varphi_0$ & General A sends a messenger to B informing them of their army's intent. \\
3. & $B_{B}I_{B,A} \varphi_0 \wedge T_{B,A} \varphi_0$ & General B believes the message from general A. \\
4. & $B_{B} \varphi_0$ & By C1. \\
5. & $B_{B} \varphi_0 \rightarrow \varphi_1$ & General B knows the plan. \\
6. & $w \vDash V_{\varphi_0}^{B}(w)$ & $V_{\varphi_0}^{B}(w)$ always returns true. \\
\end{tabular} \\~\\
Therefore, A is not MSDND secure to B. However, $V_{\varphi_1}^{A}(w) \not \in V$ , so B is secure to A.
\label{tab:twoarmiesproof}
\end{table*}

However, to process A, $V_{\varphi_{0}}^A(w)$ is undefined, so MSDND holds in that security domain. 

\begin{case}
Any number of messengers are sent and deliver their message, alternating from General A or General B to the other general. \label{case:generalsnn}
\end{case}

As each messenger arrives, the receiving general will trust the message and believe, resulting in that general assigning value to $\varphi_i$.

\begin{table*}[h!]
\centering
\begin{tabular}{r r l}
% Revise me to have some dots in me so the last step resolves n.
1. & $B_{B} \varphi_0$ & Continuing from Case \ref{case:generalsn0} \\
2. & $B_{B} \varphi_0 \rightarrow \varphi_1$ & General B decides to follow A's plan. \\
3. & $I_{A,B} \varphi_1$ & General B sends a messenger to A informing them of their army's intent. \\
4. & $B_{A}I_{A,B} \varphi_1 \wedge T_{A,B} \varphi_1$ & General A believes the message from general B. \\
5. & $B_{A}\varphi_1$ & By C1. \\
6. & $B_{A}\varphi_1 \rightarrow \varphi_2$ & General A agrees. \\
...& & The same logical chain repeats. \\
7. & $w \vDash V_{\varphi_n}^{x}(w)$ & $V_{\varphi_n}^{x}(w)$ is always true. $x$ is $A$ or $B$ depending on the value of n. %
\end{tabular} \\~\\
Therefore, either A or B is not MSDND secure to the other for $\varphi_n$.
\label{tab:twoarmiesproof}
\end{table*}

In the case $n=1$, B is now unsure that A has received $\varphi_1$ and cannot deduce if $B_{A} \varphi_1$. B is unsure of A's state and as a consequence A is MSDND secure to B. However, B is not MSDND secure to B because $\varphi_1$ is known to A. By extension For $i=2,4...n$ B is secure to A, but not A to B. For $i=3,5...n$, A is secure to B, but not B to A.

\begin{cor}
Every message exchange where some atom $\varphi_0$ is sent, followed by any number $n$ successful exchanges results in one process being insecure to the other.
\end{cor}

\begin{thm}
If a messenger is captured, if the message is not resent, both processes will be secure on the last successfully delivered message atom $\varphi_{n}$ or $\varphi_0$ if the first messenger is captured.
\end{thm}

\begin{case}
One messenger is sent and captured by the enemy.
\end{case}

%Although, the expectation of a messenger might leak something?
It should be obvious and direct that if the messenger does not arrive, it is equivalent to the messenger never being sent. (Theorem \ref{thm:nomsg})

\begin{case}
If $n-1$ messengers successfully deliver their message, but messenger $n$ is captured, both are secure on $\varphi_{n}$.
\end{case}

Suppose General A sends $\varphi_{n-1}$ to B. It should be obvious that on the delivery of the message $\varphi_{n-1}$ to B, the value of $\varphi_{n}$ is secure in B to A, as A has no way of knowing if $\varphi_{n-1}$ was delivered, unless B sends $\varphi_{n}$ with a messenger. When B does send $\varphi_{n}$, the messenger never arrives. As a consequence, General A has no way of assigning value to $B_A \varphi_n$ ($V_{\varphi_n}^A \not \in V$). However, as before, with $\varphi_{n-1}$ at A is not secure to B.

Assume that both generals know the probability that a messenger successfully makes the trip between the two armies to deliver the message, $P(m)$. When General A dispatches the messenger with $\varphi_0$ General A can infer the probability the attack will succeed to the probability the messenger delivers $\varphi_0$ to General B ($P(m)$). Since General B knows that A's model depends only on the delivery of $\varphi_0$ to B, B can deduce A's certainty that the attack will succeed. If B sends a confirmation $\varphi_1$, an identical constructed model emerges.

If we enforce a requirement that a General cannot reconsider a plan (in this case, $\varphi_0$). Then, while the receiver of the last message, $\varphi_n$, can construct the same model of the probability to attack as the sender, the recipient can construct a more accurate model given that the message delivery event has occurred. In fact, if the sender is committed to a proposed plan, for this problem the recipient the recipient can be certain the attack will succeed. We will describe processes or generals that conform to this requirement as being $stable$.

\begin{pdef}
A process is stable for an atom $\varphi$ if the value of the atom will not change after $I_{i,j} \varphi$.
\end{pdef}

\begin{pdef}
A process is stable if it is stable for every atom it transmits.
\end{pdef}

%\begin{pdef}
%A process $i$ is certain of a portion of a process's ($j$'s) state, $\varphi$ iff $I_{i,j} \varphi \wedge B_i I_{i,j} \varphi \wedge T_{i,j} \varphi$ if process $j$ is stable for $\varphi$.
%\end{pdef}

\subsubsection{More Parties}

If General A is attempting to coordinate with multiple armies, the problem becomes more complex. If we extend the messenger analogy to cover faulty generals (ones that send incorrect information or omit messengers), the generals can reach consensus if for every faulty general, there are three generals that work correctly. This is a well known result known as the Byzantine Generals problem.

\begin{thm}
In any message exchange that conforms to the constraints of the Byzantine Generals problem, all processes are MSDND insecure on the consensus'd plan $\varphi$.
\end{thm}

Proof: Suppose A decides to use plan $\varphi$ to attack. Suppose that there is some set of Byzantine Generals $Z$ and some set of loyal generals $L$ ($A \in L$). If $|L| > 3|Z|$, the algorithm executes successfully, and $B_x \varphi : \forall x \in L $. Therefore, every general in L can valuate $\varphi$ and the variable is insecure.

It is worth noting, however, that if all generals intend to behave well (they are non-byzantine) and messages are lost in transit, consensus can only be reached if the initial distribution of $\varphi$ occurs, and each general still receives enough messages to determine the majority consensus. In general, this would be impractical to ensure in an actual application.

Instead, consider a simple algorithm to reach consensus for a system with no byzantine generals, but with omission failure (message loss). Again, each message has the probability $P(m)$ of being delivered. General A distributes the plan $\varphi_0$ to $k$ other generals. If General A expects no confirmations, the probability that the message was delivered to all $k$ generals is $P(m)^k$. If the first message is delivered, the receiving processes can construct the same model as A if they know how many generals there are and the probability that the messages are delivered. 

\subsubsection{Model Construction}

So far the models have described the probability of a particular outcome of a message exchange and the consensus those models arrive at. However, for a longer algorithm with multiple exchanges and states, it is not sufficient to use the consensus probability to determine the state, for an overall view of the system because the state of the system is a probability distribution and not a fixed state.

Consider the simple consensus algorithm from before. While all the processes that receive $\varphi$ can construct the same model, that model is not sufficient for any process to determine the state of the system. However, if all the processes are stable, and a confirmation message $\varphi_{1,i}$ is sent by each process that received $\varphi_0$ then the original sender knows for certain the state of each process that sent $\varphi_{1,i}$. 

Therefore, the original process is certain of a portion of the processes that have leaked $\varphi_{1,i}$ to it.  I need to justify the correctness of the algorithm for if the originator discards part of the state.

% Construct a markov chain off the states. Show that the chain for the secure direction is incorrect?
% If A is the secure process and knows for certain what B will do
% If B is the insecure process and doesn't know what A will do. If B constructs a model
% of A's likelyhood to attack based on B's knowledge of the probability the messenger was
% not captured.
% If A and B have the same knowledge about the probability of delivery, A can construct
% the same model as B.
% BUT if the messenger is lost, both processes are secure.

%For two parties, we can follow the same construction as the Two Armies problem: if it is assumed that the two armies exchange a fixed number messages to determine when to attack, if a messenger is captured they cannot be certain of the other general's intention to attack. Then, by a logical extension, if a general knows the probability that a messenger is captured in transit (a message is lost), and the other general acts on the last agreement they sent $(\varphi_n)$, they can determine the probability that the attack will succeed. In this case, the MSDND secure general can construct a model of the behavior of the unsecure general.

%Consider the case where the generals send a predetermined number of messengers and all the messengers deliver their message. If the final message was delivered to A, B is insecure to A. Let P(b) be the probability that, to B, the message arrived successfully at A. Now B can construct a model of the probability tomorrow's attack will succeed. A knows that the message did arrive, and, assuming A also knows P(b), A can construct the same model as B.

%In the case where a messenger is lost, both processes are secure on the atom that the messenger was carrying. Assuming once again that both processes know P(b), Process B can construct a model that is messenger arrives at A. A's best model would be constructed based on the uncertainty of their message arriving at B (Noted P(a)) and the response being lost (A cannot know which event occured). However, B will also know this uncertainity and can still construct the same model as A.

%However, when there are more parties $(n>2)$, construction is not nearly as direct. Assuming there is no ability to multicast message delivery.
%everything goes tits up.


\section{Application}

EXECUTION MODEL 1 - SEMI-SYNCHRONOUS EXECUTION IN AN ENVIRONMENT WITH REAL-TIME DEADLINES


Initial analysis is presented in the context of the FREEDM DGI. The FREEDM DGI is a portion of the FREEDM project focusing on creating a distributed intelligence for controlling power electronics. As a consequence of managing the physical network of a critical infrastructure, the DGI must execute in real-time: certain actions and tasks performed by the DGI have to be completed in a specific time from.

To organize these processes, the system relies on existing clock synchronization techniques to put the system into a semi-synchronous execution environment. The DGI is divided into several modules which focus on various tasks like autonomous configuration, managing power devices and collecting data from the system. DGI's rely on synchronized clocks to begin the execution of the various tasks at the same time. This allows the message passing portions to specify deadlines to ensure that well-behaved participating processes are all working on similar tasks at the same time. For example, under the execution model as part of the autonomous configuration module, all processes begin the Leader Election Invitation Algorithm at the same time.

When reasoning about the system within the structure of the Markov Chains and MSDND security, this is a boon. A process which is too out of sync will not be able to participate effectively and so is ignored for the purpose of this work. This effectively limits the state space of the complete naive model (as all processes are in roughly the same step of the algorithm). Furthermore, a process can be sure that if message deliveries are timely (which is enforced by the real-time constraints) they can be certain of the lifetime of the inferred state.

In the following portions of the paper we present an analysis of the information leakage for the original Garcia Molina Invitation election algorithm and present how our modified version uses the MSDND information leakage to place certainty at one process in order to construct a Markov model. In particular, we wish to use the MSDND model to show that the changes show that the coordinator can infer if each process in the group considers itself a part of that process's group.

Aspect A - Group Mantencience

Aspect B - Invitations

EXECUTION MODEL 2 - ARBITRARY EXECUTION MODEL

For an arbitrary execution model, the relationships are not quite as direct. For example, while the previous execution restricted the change of state to discrete steps, in an arbitrary execution model, processes can act on any schedule they desire. Indeed without clock synchronization accounting for clocks ticking at different rates even sleep deadlines become arbitrary.

First, we encounter the problem of a process arbitrarily starting its execution. In the synchronized model, the process was restricted to the real-time schedule before it could act, ensuring that the model created by some process was not invalidated until the next time the real-time schedule dictated the state should be recreated. Suppose that the in the algorithm,  some process i constructs a model of the grouping behavior and begins to use it. If a process j with higher priority comes online, and begins an election, the model created by process i would be invalidated. 

The algorithm designer then has to answer the question: which is more important: using the created model for its lifetime or moving towards the lowest energy state. However, perhaps if we assume that these events are rare, and that ideally, these events lead the system to a better overall state, we can accept their interruption of the existing execution model.

In an arbitrary execution model, the exchange of messages can act as an unofficial sort of synchronization. When two processes exchange a query / response pair of messages, if that exchange results in the two processes working from related points in the algorithm's structure. However, as in the Two Armies problem, the state of the querying process is MSDND secure to the responding process. If a process makes an inference based on a query to another process and wishes to use that inferred information as a part of a constructed model that inferred information carries the burden of being consistent for the term of constructing the model (ie, it has a lifetime of validity for that model.)

As a consequence, only the modelling process should accept sudden changes that invalidate the model it holds. Other processes should hold onto values they leak to the modelling process for the lifetime of that model. Consider the case of the Leader Election algorithm. When a process agrees to join another processes' group, it is a reasonable expectation for that process to assume that the leader is active and working for some period of time. If after some period that process is given reason to suspect the leader process has crashed it has a reasonable allowance to do so without invalidating the leader processes' model of the group. In fact, the as part of the execution of the algorithm, the leader process makes a contract with the joined process that that process will not purposefully defy the model until the period that the model is invalidated.

Frame this idea as an extension of failure detectors and crash detection. The argument can be made that in a system where crash failures and omission failures occur, this property is particularly reasonable to use.






\bibliographystyle{plain}
\bibliography{latex_bibliography}
\end{document}

