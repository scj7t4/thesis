% Introduce the contents of the paper and what will be presented
\chapter{Introduction}

The design of stochastic models of distributed system has a long history as a challenging area of interest.
Models of distributed systems have to deal with a number of factors.
These factors include the various types of failure the system could experience, a lack of tightly synchronized execution, and a large complex state space when there are a high number of agents\cite{DISTRIBUTED}\cite{distributed-challenges}. 
However, the concept of distributed systems plays a central role in many of the future visions for how critical infrastructure will operate.
This critical infrastructures are physical networks whose operation are so vital that if those networks failed to operate correctly it would be highly detrimental to the population that rely on those systems.
\ac{CPS} describe the integration of computational systems with physical networks.
Computational systems already play a critical role in most critical infrastructures, and as demands for security features such as acessibility increase, distributed systems become an increasingly favorable choice for the computational needs for these systems \cite{SMARTGRIDBENEFITS}.

The \ac{FREEDM}\cite{FREEDM} smart-grid project follows this vision. The \ac{FREEDM} center, an NSF funded ERC envisions a future power-grid where widely distributed renewable power generation and storage is closely coupled with a distributed system that facilitates the dispatch of power across those areas. Other systems like \ac{VANET}s\cite{CARS1}\cite{CARS2} and Air traffic control \cite{AIRTRAFFIC1}\cite{AIRTRAFFIC2} also propose similar control systems where many computers must co-operate to ensure both smooth operation, and the safety of the people using those systems. Because of this, ensuring the behavior of the computer systems that control these infrastructures behaves correctly during failure is critical, especially when those computer systems rely on their interaction with other computers to operate.

A robust \ac{CPS} should be able to survive and adapt to communication network outages in both the physical and cyber domains.
When one of these outages occurs, the physical or cyber components must take corrective action to allow the rest of the system to continue operating normally.
Additionally, processes may need to react to the state change of some other process.
Managing and detecting when other processes have failed is commonly handled by a leader election algorithm and failure detector.

In a smart-grid system, misbehavior during fault conditions could lead to critical failures such as a blackout or voltage collapse. In a \ac{VANET} or air traffic control system, vehicles could collide, injuring passengers or destroying property. Additionally, since these systems are a part of critical infrastructure, protecting them from malicious entities is an important consideration.

A stochastic model for a cyber-physical system is valuable while the system is being developed, but also valuable when the system is deployed in the field. \cite{safecomp-jackson} shows an application of a stochastic model in a smart-grid system being used to harden the system to protect it from message delay caused by congestion. This hardening changed the behavior of the cyber component of the \ac{CPS} to allow its operation to continue (albeit with slightly different properties), while still protecting the physical system from errors that would have occurred, had the system continued without hardening for those errors.

Therefore, it is valuable for the cyber-physical system to make its own stochastic models online and make decisions about how the agent should behave. However, typically, a well designed model requires an omnipotent view of the system. In distributed systems, this is particularly difficult as an instantaneous snapshot of the system is not possible without perfectly synchronous execution. Furthermore, while many algorithms for casual snapshots exist\cite{distributed-challenges}, a causal snapshot may not represent a state that the system was ever in.

It is desirable then, to design distributed algorithms some agent can infer the state of other agents and generate a stochastic model of the future from those inferences. Then, using that model the agent can make decisions about how best to react to the current physical or cyber conditions that best benefits the \ac{CPS} as a whole. However, the dispersal of information in a distributed system requires messages to be passed between agents, which can be disrupted by faults\cite{HARINI}. The agent creating the stochastic model must be able to infer the state of the other agents it is attempting to model in order to create the model.

This work was motivated by observations on the effects of network unreliability on the group management module of the \ac{DGI} used by the \ac{FREEDM} smart-grid project.
These original observations confirmed the need to explore more well defined models for the behaviors of \ac{CPS} in order for them to better serve the people that use them.

As part of an analysis of omission failures, this work presents an approach in modeling the grouping behavior of a system using Markov chains.
These chains produce expectations of how long a system can be expected to stay in a particular state, or how much time it will be able to spend coordinating and doing useful work over a period of time.
Using these measures, the behavior of the cyber system can be specified to prevent faults.

In this work, we present a framework for reasoning about inferable state in the context of a distributed system. To do this we exploit existing work in the field of information flow security. Information flow security has been used to reason about how attacks like STUXNET can manipulate operators beliefs while disrupting the system\cite{STUXNET}. In particular, these approaches reason about how the operator in a STUXNET attack has no avenue to verify the reports from a compromised computing device. Using existing modal logic frameworks and using information flow security models\cite{Howser2012}\cite{STUXNET}\cite{Howser2013}, one can formally reason about where information that is not normally known to a domain can be inferred.

We will show in this work that in a system with the correct information flows, an agent in a distributed system can infer the state of other agents in the system. With this information, that agent can then construct a reasonable model of the system to determine if the current behavior could lead to an undesirable situation with either the cyber or physical network. We formalize how this flows are created using information flow security models.

Using this framework we present a leader election that is markov modelable for a set of known omission rates.
The presented algorithm maintains the Markov property for the observations of the leader despite omission\cite{OMISSIONFAILURES} failures.
This approach to considering how a distributed system interacts during a fault condition allows for the creation of new techniques for managing a fault scenario in cyber-physical systems.
These models produce expectations of how much time the DGI will be able to spend coordinating and doing useful work.
Using these measures, the behavior of the control system for the physical devices can be adjusted to prevent faults, like blackouts and voltage collapse, in the physical network.

We also propose a technique to inform distributed processes of communication network congestion.
These processes act on this information to change their behavior in anticipation of message delays or loss.
This behavior allows them to harden themselves against the congestion, and allows them to continue operating as normally as possible during the congestion.
This technique involves changing the behavior of both the leader election\cite{INVITATIONELECTION} and load balancing algorithm during congestion.

To accomplish this, we extend existing networking concepts of \ac{RED}, \ac{ECN}\cite{RFCECN}, and ICMP source quench\cite{RFCSOURCEQUENCH}.
When a network device detects congestion, it notifies processes that the network is experiencing congestion and they should react appropriately.
%Congestion management techniques have historically only been applied to TCP connections.
We propose a practical application for these techniques in scenarios where the message delay is a primary concern, not the rate at which data is sent.
%By using a rate limited UDP multicast beacon, processes are informed of the congestion level.
With this information, they can adjust their behavior to compensate for the detected congestion.

Additionally, we demonstrate an implementation of the \ac{FREEDM} \ac{DGI} in a \ac{NS3} simulation environment\cite{NS3} with our congestion detection feature.
The \ac{DGI} operates normally until the simulation introduces a traffic flow that congests the network devices in the simulation.
After congestion has been identified by the \ac{RED} queueing algorithm, the \ac{DGI}s are informed. %via UDP multicast.
We show that when the congestion notifications are introduced, the \ac{DGI} maintains configurations which they would normally be unable to maintain during congestion.
Additionally, we show a greater amount of work can be done without the work causing unstable power settings to be applied.

