% Describe why these models are useful. Show the ECN model... maybe something else.



\chapter{Application}

In this work, we consider the effects of network congestion on a cyber communication network used by the \ac{FREEDM} smart-grid.
We create a model version of a large number of \ac{DGI} processes in a simple partitioned setup.
%By applying traffic to this network, we create a situation where the network devices' queues are completely filled or real-time deadlines are missed due to queuing delays.
In  the \ac{FREEDM} smart-grid, the consequences of this congestion could result in several problematic scenarios.
First, if the congestion prevents the \ac{DGI} from autonomously configuring using its group management system, processes cannot work together to manage power devices.
Secondly, if messages arrive too late, or are lost, the \ac{DGI} could apply settings to the attached power devices that drive the physical network to instability.
These unstable settings could lead to problems in the power-grid like frequency instability, blackouts, and voltage collapse.



These techniques allow the DGI to anticipate behavior during a fault and allow it to preemptively harden itself against the fault.

\section{Application: ECN Hardening}


\subsection{Random Early Detection}
The \ac{RED} queuing algorithm is a popular queuing algorithm for switches and routers.
It uses a probabilistic model and an \ac{EWMA} to determine if the average queue size exceeds predefined values.
These values are used to identify potential congestion and manage it.
This is accomplished by determining the average size of the queue, and then probabilistically dropping packets to maintain the size of the queue.
In \ac{RED}, when the average queue size $avg$ exceeds a minimum threshold ($min_{th}$), but is less than a maximum threshold ($max_{th}$), new packets arriving at the queue may be ``marked''.
The probability a packet is marked is based on the following relation between $p_{b}$ and $p_{a}$ where $p_{a}$ is the final probability a packet will be marked.

\begin{equation}
p_{b} = max_p (avg - min_{th}) / (max_{th}-min_{th})
\end{equation}
\begin{equation}
p_{a} = p_{b} / (1-count * p_b)
\end{equation}

Where $max_p$ is the maximum probability a packet will be marked when the queue size is between $min_{th}$ and $max_{th}$ and $count$ is the number of packets since the last marked packet.
With \ac{RED}, the probability a packet is marked varies linearly with the average queue size, and as a function and the time since the last packet was marked.
If $avg$ is greater than $max_{th}$, the probability of marking trends toward 1 as the average queue size approaches $2*max_{th}$
In the event the queue fills completely, the \ac{RED} queue operates as a drop-tail queue.

In a simple implementation of the \ac{RED} algorithm, marked packets are dropped.
For a TCP application, the result of the dropped packets causes the slow-start congestion control strategy to reduce the rate packets are sent.
A more advanced implementation, using \ac{ECN}, sets specific bits in the TCP header to indicate congestion.
By using \ac{ECN}, TCP connections can reduce their transmission rate without re-transmitting packets.

UDP applications have not typically utilized \ac{ECN}.
Although the \ac{ECN} standard has flags in the IPv4 header, access to the IPv4 header is not possible on most systems.
Furthermore, there is not a ``one size fits all'' solution to congestion in UDP algorithms.
However, for the \ac{DGI} and a class of similar real-time processes, congestion notification has great potential.
If processes can adjust the amount of traffic they send based on the anticipated congestion (by disabling features, for example), they can decrease the effects of congestion.


\subsection{Usage Theory}
Since the \ac{ECN} fields in IPv4 are not available to applications running on the system, the notifications are multicast onto the source interface.
This application is responsible for generating the multicast ECN message.
It also keeps a register of hosts running applications that support reacting to the \ac{ECN} notification.

There are several reasons for this approach.
First, related work has shown an \ac{ECN} strategy without some other queue management scheme is not sufficient to prevent congestion.
By allowing real-time applications that decrease the number of messages for congestion special priority in the \ac{RED} algorithm, we allow those applications to continue operating during congestion.
Additionally, in later sections, we demonstrate this strategy is effective for managing congestion.

When the \ac{RED} algorithm identifies congestion it must notify senders of congestion.
Since this approach is non-standard and most UDP applications would not understand the notification, we have opted to create an application that runs on switches and routers.
Congestion is detected, the application sends a multicast beacon to a group of interfaces informing the attached devices of the level of congestion.
For similarity with the \ac{RED} algorithm and the \ac{NS3} implementation, this notification is classified as either ``soft'' or ``hard.''
A soft notification is an indication the congestion in the network is approaching a level where real-time processes can expect message delays that may affect their normal operation.
A hard notification indicates the congestion has reached a level where messages are subject to both delay and loss.
%The notifications are rate limited so they do not flood the network.

\subsection{Group Management}

The group management module's execution schedule is broken into several periods of message generation and response windows.
Because the schedule of the \ac{DGI} triggers the execution of group management modules approximately simultaneously, the traffic generated by modules is bursty.
The number of messages sent is $O(n^2)$ (where $n$ is the number of processes in the system), in a brief window, which is dependent on how well the clocks are synchronized in the system.
The duration of the response window is dependent on the amount of time it takes for messages to propagate to the hardest-to-reach process the \ac{DGI} hopes to group with.
Additionally, to contend with congestion, an additional slack must be added to allow the \ac{RED} algorithm to detect congestion before it reaches a critical level.
Figure \ref{fig:queue-types} depicts typical queuing behavior for a network device serving \ac{DGI} processes under different circumstances.

Because the traffic generated by \ac{DGI} modules is very bursty, the queue experiences a phenomena where the bursty traffic mixed with a steady background traffic causes the queue to fill.
With no background traffic, the impulse queues a large number of messages, but those messages are distributed in a timely manner.
When the background traffic is introduced, the queue takes longer to empty.
At a critical threshold, the queue does not empty completely before the next burst is generated by the \ac{DGI}.
In this scenario, the queue completely fills and no messages can be distributed.
The \ac{RED} algorithm and \ac{ECN} are used to delay or prevent the queue from reaching this critical threshold.

\begin{figure}
\centering
\includegraphics[width=0.4\linewidth]{QueueStacked}
\caption{
Example of network queuing during \ac{DGI} operation. \ac{DGI} modules are semi-synchronous, and create bursty traffic on the network.
When there is no other traffic on the network (solid line), the bursty traffic causes a large number of packets to queue quickly, but the queue empties at a similar rate.
With background traffic (dashed line), the bursty traffic causes a large number of packets to be queued suddenly. More packets arrive continuously, causing the queue to drain off more slowly.
When the background traffic reaches a certain threshold (dotted line), the queue does not empty before the next burst occurs. When this happens, messages will not be delivered in time, and the queue will completely fill.
}
\label{fig:queue-types}
\end{figure}

For this work, the algorithm from \cite{JOURNAL} was used.
This algorithm has a higher message complexity when in a group than the Garcia-Molina algorithm it is based on.
However, it does possess a desirable memoryless property that makes it easy to analyze.
This work uses an improved version of the algorithm which removes the restrictions in \cite{JOURNAL} where only one process could become the leader.

\subsubsection{Soft \ac{ECN}.}

A soft \ac{ECN} message indicates the network has reached a level of congestion where the router suspects processes will not be able to meet their real time requirements.
The soft \ac{ECN} message encourages the \ac{DGI} processes to reduce the number of messages they send to reduce the amount of congestion they contribute to the network, and to allow for reliable distribution techniques to have additional time to deliver messages (since fewer messages are being sent).
In the case of potential congestion, the group management module can reduce its traffic bursts by disabling elections during the congestion.
When the elections are disabled, messages for group management are only sent to members of the group.
Processes do not seek out better or other leaders to merge with.
As a consequence, the message complexity for processes responding to the congestion notification reduces from $O(n^2)$ to $O(n)$.

\subsubsection{Hard \ac{ECN}.}

In a hard \ac{ECN} scenario, the router will have determined congestion has reached a threshold where the real-time processes will soon not be able to meet their deadlines.
In this scenario, the real-time process will likely split its group.
In an uncontrolled situation, the split will be random.
It is therefore desirable when this level of traffic is reached to split the group.
Splitting the group reduces the number of messages sent across the router for modules with $O(n^2)$ (where $n$ is the number of processes in the original group) message complexity.
For larger groups, splitting them provides a significant savings in the number of messages that must be queued by the router, especially since the traffic is very bursty.

\begin{figure}
\centering
\includegraphics[width=0.35\textwidth]{NetworkLayout}
\caption{Example of process organization used in this paper. Two groups of processes are connected by a router.} \label{fig:network-layout}
\end{figure}

Suppose a network like one depicted in Figure \ref{fig:network-layout}, where processes are divided by a router.
In Figure \ref{fig:network-layout}, there are $n$ processes on one side of the network and $m$ on the other.
In normal operation the omission-modelable algorithm has an $O(n^2)$ message complexity.
In Soft \ac{ECN} maintenance mode, the reduced number of messages reduces the complexity to $O(n)$ by disabling elections.

During elections (and with each group update) the leader distributes a fall-back configuration that will coordinate the division of the groups during intense congestion.
When the \ac{ECN} notification is received the processes will halt all current group management operations and enter a splitting mode where they switch to the fall-back configuration.
The leader of the group distributes a fall-back notification to ensure all processes in the group apply their new configuration. 
The complexity of distributing the notification is linear $O(n)$ and processes that already received the notification will have halted their communication.
This approach will ideally avoid the burst/drain phenomena from figure \ref{fig:queue-types}.

The design of the fall-back configuration can be created to optimize various factors.
These factors include cyber considerations, such as the likely network path the processes in the group will use to communicate.
By selecting the group around the network resources, the group can be selected to minimize the amount of traffic that crosses the congested links in the future.
Additionally, considerations from the physical network can be considered.
Fall-back groups can be created to ensure they can continue to facilitate the needs of the members.
This can take into the consideration the distribution of supply and demand processes in the current group.
By having a good mix of process types in the fall-back group the potential for work can remain high.

\subsection{Cyber-Physical System}

For a real-time \ac{CPS}, message delays could affect coordinated actions.
As result, these actions may not happen at the correct moments or at all.
Since the two-army problem prevents any process from being entirely certain a coordinated action will happen in concert, problems arising from delay or omission of messages is of particular interest.
In particular, we are interested in the scenario from \cite{HARINI}, where only half of a power migration is performed.
Other power management algorithms could have similar effects on the power system based on this idea of a process performing an action that is not compensated for by other processes.

\subsubsection{Soft \ac{ECN}.}

In a soft congestion notification mode, the process being informed of the congestion can reduce its affect on the congestion by changing how often it generates bursty traffic.
Processes running the load balancing algorithm make several traffic bursts when they exchange state information and prepare migrations.
As shown before, if the interval between these bursts is not sufficient for the queue to drain before the next burst occurs, then critical, overwhelming congestion occurs.
Since the schedule of the \ac{DGI} is fixed at run-time processes cannot simply extend the duration of the load balancing execution phase.
However, on notification from the leader, the process can, instead, reduce the number of migrations to increase the message delivery interval.
This notification to reduce the schedule originates from the coordinator as part of the message exchange necessary for the process to remain in the group.
Every process in the group must receive this message to participate in load balancing, ensuring all processes remain on the same real-time schedule.
Using this approach, the amount of traffic generated is unchanged but the time period a process waits for the messages to be distributed is increased.

\subsubsection{Hard \ac{ECN}.}

When the \ac{DGI} process receives a hard congestion notification, the processes switch to a predetermined fall-back configuration.
This configuration creates a cyber partition.
By partitioning the network, the number of messages sent by applications with $O(n^2)$ message complexity can be reduced significantly.
Each migration of load balancing algorithm begins with an $O(n^2)$ message burst and so benefits from the reduced group size created by the partition.

Suppose there is a network like the in Figure \ref{fig:network-layout} with $n$ processes on one half and $m$ on the other.
The number of messages sent across the router for the undivided group is of the order $2mn$ as the $n$ processes on side A send a message to the $m$ on side B and vice-versa.
Let $i_{1}$ and $j_{1}$ be the number of processes from side A and side B (respectively) in the first group created by the partition.
Let $i_{2}$ and $j_{2}$ be the number of processes in the second group created by the partition under the same circumstances of $i_1$ and $j_1$.
The number of messages sent that pass through the router, is then 

\begin{equation}
2 i_{1} j_{1} + 2 i_{2} j_{2}
\end{equation}

For an arbitrary group division, the following can be observed.
Suppose $i_{1}$ and $j_{2}$ are the cardinality of two arbitrarily chosen sets of processes from side A and side B respectively.
Following the same cut requirements as before:

\begin{equation}
i_2 = n - i_1 \text{ and } j_2 = m - j_1
\end{equation}

The number of messages that must pass through the router for this cut is:

\begin{equation}
2 i_{1} j_{1} + 2 (n-i_{1}) (m-j_{1})
\end{equation}

The benefits of the cut are minimized when $i_1$ and $j_1$ are $\frac{n}{2}$ and $\frac{m}{2}$:

\begin{equation}
2( 2 \frac{mn}{4} + mn - \frac{mn}{2} - \frac{mn}{2}) = mn
\end{equation}

Which is a reduction of half as many messages.
For systems with a large number of participating processes this represents a significant reduction in the number of messages sent across the router.
As a consequence, this further extends the delivery window for processes sending messages.

\subsection{Relation To Omission Model}

The synchronization of clocks in the environment is assumed to be normally distributed around a true time value provided by the simulation.
The shape of the curve created by plotting the queue resembles that of the \ac{CDF} of the normal distribution, noted $F(x)$.
A simple description of the traffic behavior can then be described in terms of that curve.
First, observe that when the queue hits a specific threshold, even if the queue is drained at an optimal rate, the $n$th queued packed will not be delivered in time:

\begin{equation}
Qsize - min(Qsize, (DequeueRate * \Delta t)) \geq 0
\label{eq:origin}
\end{equation}

Where $\Delta t$ is the deadline for the message to be delivered.
If the size of the queue exceeds the number of messages that can be delivered before $\Delta t$ passes, some messages will not be delivered.
The size of the queue during the message bursts created by the DGI depends on the message complexity of the algorithm, the number of messages already in the queue, the other traffic on the network, and any replies that also have to be delivered in that interval.
Therefore, let $c$ represent the rate that traffic is generated by other processes.
Let $init_q$ represent the number of messages in the queue at the start of a burst. 
Let $init_m$ represent the number of messages sent in the beginning of the burst.
Let $resp$ represent the number of messages sent in response to the burst that must still be delivered before $\Delta t$ passes.
We can then express $Qsize$ as two parts:

\begin{equation}
Qsize = Burst + Obligations
\end{equation}

Where $Burst$ takes the form of the \ac{CDF} for the normal distribution:

\begin{equation}
Burst = init_m * F(x)  
\end{equation}

\begin{equation}
Obligations = c * \Delta t + init_q + resp
\end{equation}

From this we can derive the equation:

\begin{equation}
F(x) \geq \frac{DequeueRate * \Delta t - c * \Delta t - init_q - resp}{init_m}
\label{eq:prob-est}
\end{equation}

Where, from Equation \ref{eq:origin}, $DequeueRate * \Delta t$ is less than or equal to the number of messages in the queue. 
Solving for $F(x)$ gives a worst case estimate of the omission rate for a specific algorithmic or network circumstance.
$DequeueRate$ is affected by the amount of traffic in the system. 
It should be obvious a greater amount of background traffic corresponds to a greater average queue size.
From an relationship between the background traffic and the average queue size and the results presented in \cite{JOURNAL}, Equation \ref{eq:prob-est} can be used to select the ECN parameters.


\subsection{Calibration}

Since the distribution of clock synchronization was selected to be a normal distribution, the shape of the curve created by plotting the queue resembles that of the \ac{CDF} of the distribution, noted $F(x)$.
A simple description of the traffic behavior can then be described in terms of that curve.
First, observe that when the queue hits a specific threshold, even if the queue is drained at an optimal rate, the $n$th queued packed will not be delivered in time:

\begin{equation}
Qsize - (DequeueRate * \delta t) \geq 0
\end{equation}

Where $\delta t$ is the deadline for the message to be delivered.
If the size of the queue exceeds the number of messages that can be delivered before $\delta t$ passes, some messages will not be delivered.
The size of the queue during the message bursts created by the DGI depends on the message complexity of the algorithm, the number of messages already in the queue, the other traffic on the network, and any replies that also have to be delivered in that interval.
Therefore, let $c$ represent the rate that traffic is generated by other processes.
Let $init_q$ represent the number of messages in the queue at the start of a burst. 
Let $init_m$ represent the number of messages sent in the beginning of the burst.
Let $resp$ represent the number of messages sent in response to the burst that must still be delivered before $\delta t$ passes.
We can then express $Qsize$ as two parts:

\begin{equation}
Qsize = Burst + Obligations
\end{equation}

Where $Burst$ takes the form of the \ac{CDF} for the normal distribution:

\begin{equation}
Burst = init_m * F(x)  
\end{equation}

\begin{equation}
Obligations = c * \delta t + init_q + resp
\end{equation}

From this we can derive the equation:

\begin{equation}
F(x) \geq \frac{DequeueRate * \delta t - c * \delta t - init_q - resp}{init_m}
\end{equation}

Solving for $F(x)$ gives a worst case estimate of the omission rate for a specific algorithmic or network circumstance.


% RESULTS
%   - Show the unbounded Queue Graph and the mess it makes of LB and GM
%   - Show soft ECVN allows more work to be done, possibly at the cost of accumulating K.
%   - Shwo that HARD ecn allows the best operation -- work gets done and less K is accumlated.

% Show a control. 
% Normal operation. Highlight the bursty peaks from the \ac{DGI} algorithm running
% Point out the average queue size as a second line.
% State a relationship between the average queue size and the message delay.

% Introduce a sufficent amount of traffic to make the queue drain off slowly, recreating the previous figure
% State again that as the amount of other traffic increases the time to drain the queue starts to increase
% State that this does not affect normal operation because the \ac{DGI} has slack built into the schedule to ensure that a normal amount of background traffic does not cripple the \ac{DGI}.
% State that as the traffic increases further, eventually it will over flow the queue
% Show the unbounded queue growth for a drop tail queue.

% Introduce the \ac{RED} queue.
% Show that the \ac{RED} queue, without notifying the \ac{DGI} can do some management, but it isn't sufficent to keep the groups together.
% Show that based on the control, less work gets done and the groups change more frequently.

% Introduce the \ac{ECN} notification
% If the \ac{RED} queue allows \ac{DGI} traffic to pass (making the \ac{RED} queue more like a drop-tail for \ac{DGI} traffic) show that it improves on the previous scenario.
% Show that however, eventually the traffic reaches a threshold where the stratedgy is not sufficent to prevent issues.
% Introduce the \ac{DGI} reacting to the notifications.
% Show that when the \ac{DGI} goes into a maintain mode the average traffic drops.
% Show that this allows a large group to be maintained and the migrations to proceed as normal (with the time reduced schedule).

% Introduce HARD groupbreaks.
% Show that a hard group break greatly reduces traffic (even more than previously) & that this allows the \ac{DGI} to determine how to split.
% Demonstrate a worst-case scenario where the group break is not optimal.
% Show that a planned hard break allows that group to continue operating.

\section{Proof Of Concept}

\subsection{Experimental Setup}
\label{sect:experimentalsetup}

Experiments were run in a Network Simulator 3.23\cite{NS3} test environment.
The simulation time replaced the wall clock time in the \ac{DGI} for the purpose of triggering real-time events.
As a result, the computation time on the \ac{DGI} for processing and preparing messages was neglected.
However, to compensate for the lack of processing time, the synchronization of the \ac{DGI} was instead randomly distributed as a normal distribution.
This was done to introduce realism to ensure events did not occur simultaneously.
Additionally, the real-time schedules used by the \ac{DGI} were adjusted to remove the processing time that was neglected in the simulation.

The \ac{DGI} were placed into a partitioned environment.
The test included 30 nodes.
Each of the nodes ran one \ac{DGI} process.
Two sets of 15 \ac{DGI} were each connect to a switch and each switch was in turn connected to the router.
This network is pictured in Figure \ref{fig:network-layout}.
Node identifiers were randomly assigned to nodes in the simulation and used as the process identifier for the \ac{DGI}.

The links between the router and the switches had a \ac{RED} enabled queue placed on both network interfaces.
The \ac{RED} parameters for all queues were set identically.
A summary of \ac{RED} parameters are listed in Table \ref{tab:red-parameters}.
All links in the simulation were 100Mbps links with a 0.5ms delay.
RED was used in packet count mode to determine congestion.
ARP tables were populated before the simulation began.
\ac{RED} parameters were selected using results from \cite{JOURNAL}.

The relationship between the background traffic and the average queue size was estimated through runs of the \ac{NS3} simulation.
Figure \ref{fig:plotm} demonstrates the observed relationship between the total background traffic and the maximum average queue size for that level of traffic.
Additionally, the $DequeueRate$ was collected from a run of the simulation without traffic, and was found to be $713.08$ packets/second.
Therefore, from Equation \ref{eq:prob-est}, assuming $init_q=0, resp=225, init_m=225$ and $\Delta t=1$, the maximum traffic rate with no omissions is $263.0$ packets/second.
The number of packets for the $resp$ and $init_m$ were selected from the worst case of the algorithm in \cite{JOURNAL}.
Based on the traffic parameters in Table \ref{tab:red-parameters}, $263.0$ packets/second corresponds to 1.077 Mbps of traffic generated at one switch and 2.1545 Mbps traffic overall.
From the polynomial estimate in Figure \ref{fig:plotm}, the maximum average queue size for that level of traffic is $94.715$, estimated as $90$ for the \ac{RED} Min Threshold in Table \ref{tab:red-parameters}.
RED Max Threshold is computed using a similar technique, but using the message complexity for the Load Balancing algorithm, since it maintains its complexity during Soft ECN mode.

\begin{figure}
\centering
\includegraphics[width=0.65\linewidth]{m-max-average-queue.pdf}
\caption{Plot of the maximum observed average queue size as a function of the overall background traffic. The polynomial estimate is $y=22.70x^2-44.74x+85.72$}
\label{fig:plotm}
\end{figure}

\begin{table}
\begin{center}
\begin{tabular}{ | l | l || l | l | } \hline
Parameter & Value & Parameter & Value        \\ \hline
RED Queueing Mode & Packet & RED Gentle Mode & True    \\ \hline
RED $Q_{w}$ & 0.002 & RED Wait Mode & True      \\ \hline
RED Min Threshold & 90 & RED Max Threshold & 130   \\ \hline
%Maximum Queue Size & 1000 \\ \hline
RED Link Speed & 100 Mbps & RED Link Delay & 0.5 ms   \\ \hline
%Clock Distribution $\sigma$ & 0.005 & Traffic Packet Size & 512 Bytes \\ \hline
\end{tabular}
\end{center}
\caption{Summary of \ac{RED} parameters. Unspecified values default to the \ac{NS3} implementation default value}
\label{tab:red-parameters}
\end{table}

To introduce traffic, processes attached to each of the switches attempted to send a high volume of messages to each other across the router.
The number of packets sent per second was a function of the data rate and the size of the packets sent.
In each simulation, half of the traffic originated from each switch.
Due to the bottleneck due to the properties of the network links, the greatest queueing effect occurred at the switches.

\subsection{Results}
\label{sect:results}
Figures \ref{fig:plota} and \ref{fig:plotb} show the normal operation of the system.
In this configuration, there is no congestion on the network. 
The \ac{DGI} start, group together and then begin migrating power between processes.
Figure \ref{fig:plota} plots the queue size over time for a queue used to send packets from a switch to the router.
Figure \ref{fig:plotb} is a detailed view of a portion of Figure \ref{fig:plota}.
Figure \ref{fig:plotb} shows the queue size during the normal operation of group management as well as the first migration of the load balancing module.
The dotted line plots the \ac{EWMA} of the size of the queue.

\begin{figure}
\centering
\adjustbox{valign=t}{
\begin{minipage}{.48\linewidth}
\centering
\includegraphics[width=\textwidth]{a-qsizeot-notraffic-all.pdf}
\caption{Plot of the queue size for a queue from switch A to the router when only the DGI generates traffic.}
\label{fig:plota}
\end{minipage}}%
\hfill
\adjustbox{valign=t}{
\begin{minipage}{.48\linewidth}
\centering
\includegraphics[width=\textwidth]{b-qsizeot-notraffic-120s-130s.pdf}
\caption{Detailed view of Figure \ref{fig:plota}. The left most peak is from Group Management, and the 3 smaller peaks are from power migrations.}
\label{fig:plotb}
\end{minipage}}
\end{figure}

\begin{figure}
\centering
\adjustbox{valign=t}{
\begin{minipage}{.48\linewidth}
\centering
\includegraphics[width=\textwidth]{e-qsizeot-nonotifications-2mbpstraffic-120s-130s.pdf}
\caption{Detailed view of the effect on queue size as other network traffic is introduced. Compared to Figure \ref{fig:plotb}, the peaks are taller and wider. Background traffic causes the average queue size to be updated more frequently.}
\label{fig:plote}
\end{minipage}}%
\hfill
\adjustbox{valign=t}{
\begin{minipage}{.48\linewidth}
\centering
\includegraphics[width=\textwidth]{f-qsizeot-nonotifications-4mbpstraffic-120s-130s.pdf}
\caption{Detailed view of the effect on queue size as other network traffic is introduced. With no \ac{ECN} notifications, the peak from Group Management is much larger. The congestion is sufficient that the Group Management and Load Balancing modules are affected.}
\label{fig:plotf}
\end{minipage}}%
\end{figure}

From this experiment we establish the $min_{th}$ value used as a \ac{RED} queue parameter.
The traffic generated by each step of the group management algorithm is very bursty.
It should be obvious that the tightness of the clock synchronization in the group affect how large this peak is.
Like \cite{HILTESTBED}, the level of the power at a process is the net sum of its power generation capability and load.
As power is shared on the network, processes with excess generation, converge toward zero net power.
Demand processes also converge toward zero net power.

\begin{figure}
\centering
\adjustbox{valign=t}{
\begin{minipage}{.48\linewidth}
\includegraphics[width=\textwidth]{i-qsizeot-softnotifications-4mbpstraffic-120s-130s.pdf}
\caption{Detailed view of the effect on queue size as other network traffic is introduced. In this scenario, the ECN notifications put Group Management into a maintenance mode that reduces its message complexity and switches Load Balancing to slower migration schedule, preventing undesirable behavior.}
\label{fig:ploti}
\end{minipage}}%
\hfill
\adjustbox{valign=t}{
\begin{minipage}{.48\linewidth}
\centering
\includegraphics[width=\textwidth]{k-qsizeot-softnotificationsonly-64mbpstraffic-120s-130s.pdf}
\caption{Detailed view of the effect on queue size as a large amount network traffic is introduced. Groups are unstable and processes occasionally leave the main group. Some migrations are lost due to queueing delays.}
\label{fig:plotk}
\centering
\end{minipage}}
\end{figure}

\begin{figure}
\centering
\adjustbox{valign=t}{
\begin{minipage}{.48\linewidth}
\centering
\includegraphics[width=\textwidth]{l-qsizeot-allnotifications-64mbpstraffic-120s-130s.pdf}
\caption{Effect on queue size as a large amount of network traffic is introduced. Hard notifications cause the groups to divide. As a result of the smaller groups, the group management and load balancing peaks are smaller than those in \ref{fig:plotk}. No migrations are lost.}
\label{fig:plotl}
\end{minipage}}%
\hfill
\adjustbox{valign=t}{
\begin{minipage}{.48\linewidth}
\centering
\includegraphics[width=\textwidth]{g-lostm-nonotifications-4mbpstraffic-all.pdf}
\caption{Count of lost migrations from all processes over time. Migrations are counted as lost until the second process confirms it has been completed. Without congestion management, a large number of migrations are lost.}
\label{fig:plotg}
\end{minipage}}
\end{figure}

Figure \ref{fig:plote} shows the queue size as the network traffic begins to increase.
The \ac{DGI} in these experiments use a schedule that allows for some congestion to occur before processes are disrupted.
This slack gives the network devices the opportunity to identify when the network congestion will go beyond the acceptable threshold.

Figure \ref{fig:plotf} shows an example of congestion affecting the physical network without \ac{ECN}.
As a result of the congestion in Figure \ref{fig:plotf}, processes leave the main group.
Additionally power migrations are affected: migrations are lost, or the supply process is left uncertain of migrations completions.
Figure \ref{fig:plotg} plots the count of failed migrations over time.
%In this scenario, only XXX migrations are completed compared to the control.

Figure \ref{fig:ploti} shows an example of the \ac{ECN} algorithm notifying processes of the congestion.
Compared to the scenario in Figure \ref{fig:plotf}, the \ac{ECN} algorithm successfully prevents the group from dividing, and increases the number of migrations by reducing the number of attempted migrations each round.

Figures \ref{fig:plotl} and \ref{fig:plotk} show an example of a more extreme congestion scenario.
In Figure \ref{fig:plotl}, the \ac{RED} algorithm shares a Hard \ac{ECN} notification.
This notification causes the \ac{DGI} to switch to a smaller fall-back configuration.
This fall-back configuration decreases the queue usage from Figure \ref{fig:plotk} to Figure \ref{fig:plotl}.
Without this fall-back configuration behavior, the system is greatly affected by the traffic.
However, with the fall-back configuration the system remains stable and no migrations are lost.

%Table X summarizes the number of migrations and number of failed migrations for each of the presented scenarios.
