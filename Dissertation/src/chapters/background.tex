\chapter{Background}

\section{Distributed Systems}

Distributed systems are a computing paradigm characterized by independence of computational units and no universal clock.
Components in a distributed system may not directly share computational resources or memory.
Instead, computers in a distributed system typically interact through a message passing interface.

As a result, distributed computing is a challenging area of research.
In a distributed system, since processes do not share a universal clock, the ordering of messages and events needed to be carefully considered to ensure correct operation of the system.
Additionally, since individual components fail, determining which components fail is also difficult in a distributed system.
Different types of failures can cause different kinds of information to be withheld from processes or changed to disrupt those processes.

\section{Execution And Communication Models}

In this work we consider a distributed system where no processes in the system share an address space.
All processes must use a message passing interface in order to communicate with other processes to exchange information.
As a result of the complexities of distributed systems, various execution models have been developed to define how the execution of a distributed system proceeds.
Different execution models exchange how easy it is to reason about the system's execution and the types of algorithms that can be executed for how complicated they are to implement.
We describe the avenues between processes as channels.
A channel is classified as reliable if:

\begin{axm}
    \label{axm:reliable-channel-sender}
    Every message sent by a sender is received by a receiver and every received message was sent by a sender in the system. \cite{DISTRIBUTED}
\end{axm}

\begin{axm}
    \label{axm:reliable-channel-delay}
    Every message has an arbitrary but not infinite propgation delay.\cite{DISTRIBUTED}
\end{axm}

\begin{axm}
    \label{axm:reliable-channel-fifo}
    Every channel is a \ac{FIFO} channel. If process $P$ sends a messages $x$ and $y$ to $Q$ (in that order) then $Q$ receives the messages in order ($x$ then $y$).\cite{DISTRIBUTED}
\end{axm}

These are often referred to as synchronous channels.
In this work however, channels are not assumed to be perfectly reliabile.
Instead, we respect Axiom \ref{axm:reliable-channel-fifo}, partially fulfill Axiom \ref{axm:reliable-channel-sender}, and disregard Axiom \ref{axm:reliable-channel-delay}.
Therefore, we assume the following about communication channels in the systems modelled (replacing Axiom \ref{axm:reliable-channel-sender})

\begin{axm}
    Every message received by a receiver was sent by a sender in the system.
\end{axm}

As well as Axiom \ref{axm:reliable-channel-fifo}.
Without the constrained propogation delay from \ref{axm:reliable-channel-delay}, this type of communication channel is typically referred to as an asynchronous channel.

Clocks are considered synchronized if every clock in the system reads the same time.
Since it is impossible for independent clocks to tick at the same rate, weak synchronization is used to describe when clocks in the system have an upperbound on drift rate from eachother.

The communication model can be synchronized or asynchronous.
In the synchronous communication model, processes can only send a message when the receiving process is ready to receive it.
Algorithmically, a synchronous model is usually considered a ``blocking'' operation, meaning that once a process tries to send a message, it cannot proceed until the message is received.
In this work, communication is asynchronus, meaning that a process does not wait for the successful delivery of a message.
This is known as a non-blocking send.

In a system with synchronous processes, processes execute in lockstep.
At each step a process executes its next available action.
Synchronous execution requires tight organization of the processes executing the algorithm.
In this work we generally rely on semi-synchronous execution by processes where execution proceeds in rounds or phases.
The start of each round or phase is synchronized between processes, using a synchronized clock.

\section{Faults, Failures, and Errors}

Processes can encounter incorrect behavior or issues during execution.
Errors, faults, and failures describe the severity and consequence of the issue.

DEFINITION - ERROR

An error is a difference between what is considered ``correct'' output for a given component, and the actual output-- an incorrect result.

DEFINITION - FAULT

The manefestation of an error in sofware, or an incident where a incorrect, step, or data definition is performed in a computer program.

DEFINITION - FAILURE

The inability for a component or system to perform its required function or within its specified limits.

\subsection{Crash or Fail-Stop Failure}

A crash failure or its more generalized form, a fail-stop failure, describes a failure in which a process stops executing.
In general, this is considered to be an irreversible failure, since a process typically does not resume from a crashed state.
There are categorizations of crash failures, called napping failure where a process will appear to have crashed for a finite amount of time before resuming normal operation.
Crash failures are impossible to detect with absolute certainty in an asynchronous system.
Processes can be suspected by other processes through the use of challenge/response messages or heartbeat messages that allow a process to prove that it has not crashed yet.
A system that can handle a crash failure is implied to be able to handle a fail-stop failure.\cite{DISTRIBUTED}

The fail-stop failure has three properties \cite{DISTRIBUTED}:

\begin{enumerate}
\item When a failure occurs the program execution is stopped.
\item A process can detect when another fail-stop process has failed.
\item Volatile storage is lost when the fail-stop process is stopped.
\end{enumerate}

\subsection{Omission Failure}

An omission failure occurs when a message is never received by the receiver.
Omission failures can occur when the communication medium is unavailable or when the latency of message exceeds a timeout for its expected delivery.
Protocols like TCP do not tolerate omission failures: a packet is resent until it is acknowledged by the receiver.
If the acknowledgment never comes, the connection is closed.
As a contrast, UDP assumes that any datagram could be lost and it is the responsibility of the programmer to handle missing datagrams appropriately.
An omission failure can have the same observable affects as a napping failure in some situations. \cite{DISTRIBUTED}


\subsection{Failure Detectors}

Failure detectors \cite{FAILUREDETECTORS} (Sometimes referred to as unreliable failure detectors) are special class of processes in a distributed system that detect other failed processes. Distributed systems use failure detection to identify failed processes for group management routines. Because it isn't possible to directly detect a failed process in an asynchronous system, there has been a wide breadth of work related to different classifications of failure detectors, with different properties. Some of the properties include\cite{FAILUREDETECTORS}:

\begin{itemize}
    \item Strong Completeness - Every faulty process is eventually suspected by
        every other working process.
    \item Weak Completeness - Every faulty process is eventually suspected by 
        some other working process.
    \item Strong Accuracy - No process is suspected before it actually fails.
    \item Weak Accuracy - There exists some process is never suspected of failure.
    \item Eventual Strong Accuracy - There is an initial period where strong
        accuracy is not kept. Eventually, working processes are identified
        as such, and are not suspected unless they actually fail.
    \item Eventual Weak Accuracy - There is an initial period where weak
        accuracy is not kept. Eventually, working processes are identified
        as such, and there is some process that is never suspected of failing
        again.
\end{itemize} 

One class of failure detectors, Omega class Failure detectors, are particularly interesting because of \cite{LEADERELECTIONEVAL}. An eventual weak failure (weak completeness and eventual weak accuracy) detector is the weakest detector which can still solve consensus. It is denoted several ways in various works including $\diamond \mathcal{W}$ \cite{FAILUREDETECTORS}, $\mathcal{W}$ \cite{WEAKESTFAILURE1} \cite{WEAKESTFAILURE2} and $\Omega$ (Omega) \cite{LEADERELECTIONEVAL}.

\cite{LEADERELECTIONEVAL} studies an Omega class failure detector using OmNet++\cite{OMNET}, a network simulation software package. Instead of omission failures, however, it considers crash failures. Each configuration goes through a predefined sequence of crash failures. OmNet++ is used to count the number of messages sent by each of three different leader election algorithms. Additionally, \cite{LEADERELECTIONEVAL} only considers the system to be in a complete and active state when all participants have consensus on a single leader.

\subsection{Byzantine Failures}

In a Byzantine failure, processes in the distributed system intentionally send information that is incorrect or misleading to other processes.
Contraints for detecting processing that exhibit Byzantine behavior is a famous result in the world of distributed systems.

\section{Probability}

DEFINITION Expected Value

The expected value represents the long-term average output of a probability distribution.

\begin{equation}E[X] = x_1 p_1 + x_2 p_2 + ... + x_k p_k \end{equation}

Conceptually, the expected value is the weighted average of the outcomes of some stocastic system.

DEFINITION Availability

The probability a system or component is operational and accessible when required for use, denoted $A$.

\begin{equation}A = \frac{E[uptime]}{E[uptime]+E[downtime]}\end{equation}

DEFINITION Reliability

The ability of a system or component, in specified conditions, to be able to perform its required functions for a specified period of time.

\begin{equation}R(t) = \Pr(T > t) = \int_t^{\inf} f(x) dx\end{equation}

Where $R(t)$ is the probability that the system or component functions up until at least time $t$ and $f(x)$ is the probability density function for the component's survival.

\section{Markov Models}

%When Markov chains work to model a system. Something about order of Markov chain. State what a Markov chain and the properties of the Markov chain. State what states mean. state what transition probabilies mean. State what ergodicity is. State what stationarity is. State how we generate the sequence of states.

A Markov chain is a collection of states and probabilistic transitions between those states.
States in a Markov chain are mutually exclusive.
In a Markov chain, when a system is some state $i$ it has some probability of transitioning to some other state $j$ at the next time-step.
A Markov chain is a first order chain if the probability of transitioning from $i$ to $j$ does not depend on the history of transitions that lead to state $i$.
First order chains are described as having a memoryless or Markov property.
This formalizes the independence of the next state from the history of previous states.
The Markov property describes a Markov chain as a sequence of random variables $X_{1}, X_{2}, X_{3}, ...$ and states the value of $X_{n+1}$ only depends $X_{n}$: \cite{MARKOV3}

\begin{align} \Pr(X_{n+1}&=x\mid X_1=x_1, X_2=x_2, \ldots, X_n=x_n)
\nonumber \\ &= \Pr(X_{n+1}=x\mid X_n=x_n). \end{align}

\subsection{Discrete Time Markov Chain}

An ergodic Markov chain is a chain where it is possible, in some finite number of steps, to go from any state to any other state.
A stationary Markov chain is one where the transition probabilities do not change over time.
In a stationary Markov chain, the $n$th visit to a state is indistinguishable from the $n+1$th visit to a state.

A Markov chain with $m$ states can be represented by a $m\times m$ matrix.
For simplicity when creating the model, matrices in this work are 1-indexed.
In a matrix $P$, the value of $P_{ij}$ represents the probability of the transition from $i$ to $j$.
It should be obvious the sum of each row in the matrix is equal to one:

\begin{equation} \sum_{i=1}^{m} P_{ij} = 1. \end{equation}

A useful companion to the transition matrix is a state distribution vector.
While the transition matrix describes how system will transition between states, the state distribution vector describes the probability of observing a given state.

\begin{pdef}
A state distribution vector is an $m$-dimensional vector composed of probability of observing each state in the system at a given instant:
\[ [P_{1} \quad P_{2} \quad \ldots \quad P_{m} ] \]
Where $P_{i}$ corresponds to the probability of observing state $i$.
\end{pdef}

A Markov chain is a suitable model for a memoryless random process with a finite number states which is observed at fixed time intervals.
By utilizing a Markov chain, a variety of statistical analyses can be performed on these modeled system.
For example, a Markov chain with the stationary and ergodic properties can be analyzed for its steady state probabilities.
The steady state is a state distribution vector that describes the probability a random observation of a long-running process will observe some state $i$.
The steady state can by found via a system of equations: \cite{MARKOV3}

\begin{align}
0\leq\pi_j\leq1.0 \\
\sum_{j = 1}^{m}\pi_j = 1.0 \\
\pi_j = \sum_{i=1}^{m} \pi_i p_{ij}
\end{align}

In the following sections, the computation of the steady state will be noted as $Steady()$.
A Markov chain can also be used to predict what state a process will be in at some point in the the future.
Given a initial state and a number of time-steps a matrix operation will yield the likelihood of the process being in each state after the time interval has passed.
The mean passage time, a measure of how many time-steps will pass before a process returns or arrives to some state, can also be calculated.

We model a leader election algorithm with a closed form representation of the behavior of the algorithm.
This closed form representation is a profile Markov chain (noted as $P$).
The profile Markov chain is validated against a chain generated from execution of the algorithm.
The chain constructed from sampled data is known as a test chain (noted as $T$).

\subsection{Continous Time Markov Chain}

The model begins in some initial state, and then transitions into other states based on the probabilities assigned on each edge of the graph.
Each state is memoryless, meaning that the history of the system, or the previous states have no effect on the next transition that occurs.
Letting $F_X(s)$ equal the complete history of a Markov chain $X$ up to the state $s$, and $j \in S$, where $S$ is the complete set of states in the model, then the probability of transitioning to the next state $j$ ($X_{n+1}=j$) only depends on the current state $s$ ($X_{n}$): \cite{MARKOV2} 

\begin{equation}
P\{ X_{n+1}=j | F_{X}(s) \} = P\{ X_{n+1}=j | X_{n} = s) \}
\end{equation}


Additionally, the models we present are time homogeneous, meaning that the time that transition probabilities are not affected by the amount of time that has passed in the simulation.
Let $X(s) = i$ indicate the model is in state $i$ at time $s$.
If the model is time homogenous, then the probability of transitioning to state $j$ only depends on the time spent in that state ($t$).

\begin{equation}
P\{ X(s+t)=j | X(s) = i \} = P\{ X(t)=j | X(0) = i \}
\end{equation}

Each transition has some expected value or holding time which describes the amount of time before a transition occurs.
Continuous time models do not have transitions that return to the same state since the expected value of the transition time describes when how long the system  remains in the same state.
The probability density function (PDF) of the exponential distribution can be written as: \cite{MARKOV1}

\begin{equation}
f(x;\lambda) = \begin{cases}
\lambda e^{-\lambda x} & x \ge 0 \\
0 & x < 0
\end{cases}
\end{equation}

As a result, the expected or mean value of an exponential distribution, is a function of
the parameter $\lambda$: \cite{MARKOV1}

\begin{equation}
\mathrm{E}[X] = \frac{1}{\lambda}. \!
\end{equation}

When there are multiple possible transitions from a state, each with their own expected transition time, the expected amount of time in the state is \cite{MARKOV2}
\begin{equation}
\sum \lambda(x,y) = \sum \lambda p_{x,y} = \lambda(x)
\end{equation}
where $\lambda(x,y)$ is the expected amount of time before state $x$ transitions to state $y$.
Interestingly, the expected time in a state ($\lambda(x)$) is related to the expected time for an individual transition ($\lambda(x,y)$) by a probability $p_{x,y}$.

Each transition lends to an expected amount of time in the state.
To do a random walk of a continuous time Markov chain, an intensity matrix must also be generated in order to describe which transition is taken after the exponentially distributed amount of time in the state has passed.
Consider then two streams of random variables.
One is exponentially distributed and used to determine the amount of time in a state.
The second stream is normally distributed and used to determine which state to transition to through the intensity matrix.

\section{Information Flow}

\subsubsection{Modal Logic}

Kripke frames\cite{kripke1959}\cite{blackburn2002modal} play a critical role in the development of this work. The essential concept of this work is that each global state of the distributed system at any given instant can be captured as a countably infinite set of propositional variables. A Kripke frame is a pair $<W,R>$\cite{french2006} such that W is a set of of possible versions of the global state over time, where each element in $W$ is known as a world. Each element of $R$ describes a binary relationship for how the described system can move from world to world as events occur in the described system.

In the case of a distributed system, a world could be described as one the possible combinations of values of all boolean state variables $S=\{s_0, s_1, ... s_n\}$ in that system. As execution occurs, messages, time, or events cause these variables to change. Each change in boolean variables corresponds to a relationship in $R$\cite{Gehrke200565}. Therefore, a world $w$ is one possible valuation of all the variables in $S$ and a transition from $w$ to another $w'$ (with its own valuation) can be noted as $wRw'$. Without loss of generality, each relationship in $R$ must result in the change of at least one variable in $S$. Additionally, the set of world is complete: every possible combination is represented in the set of worlds. No relationship can lead to a world that does not exist.

Additionally, we can define a set of valuation functions, $\{V\}$. Each function $V^i_{s_x}$ in $V$ describes the value observed by an agent $i$ of a boolean state variable $s_x$.  If a valuation function for a particular state variable is not defined for an agent, that agent cannot determine the value of that state variable, and cannot determine the value of any logical statement based on that variable. In the case of a distributed system, this concept is analogous to the isolation of memory for each agent. For example, an agent $i$, cannot simply determine the value of a variable for agent $j$.

The combination of a Kripke Frame $< W,R >$ and a set of valuation functions ${V}$ is a Kripke Model $M = \{W, R, V\}$ sometimes known as a modal model. The complete model describes all the possible worlds, the relation between those worlds and the information available in the domains of the system.

Let $\varphi \in \Phi_0$ be an atomic proposition in a set of countably many propositions. The set of well-formed formulas (wffs) as defined by the formulation rules in \ref{tab:axiomatic} is the least set containing $\Phi_0$. Additionally, we use the modal operator $\Box$ as an abbreviation for $\neg \Diamond \neg \varphi$. The complete axiomatic system is outlined in \ref{tab:wffs}. For the uninitiated, the modal box operator ($\Box$), ``it is necessary that'' states (in the case of $\Box \varphi$) that in every world $w$, $\varphi$ is true. As its dual, the diamond operator ($\Diamond$) states, that it is not the case that in every world, $\varphi$ is true.

\begin{table}[]
\small
\centering
\caption{Logical Statement Formulation Rules}
\begin{tabular}{r l}
1. & if $\varphi$ is a wff, so are $\neg \varphi$, $\Box \varphi$, and $\Diamond \varphi$. \\
2. & if $\varphi$ is a wff, so are $B_i \varphi$ and $\neg B_i \varphi$ \\
3. & if $\varphi$ is a wff, so are $T_{i,j} \varphi$ and $\neg T_{i,j} \varphi$ \\
4. & if $\varphi$ is a wff, so are $I_{i,j} \varphi$ and $\neg I_{i,j} \varphi$ \\
5. & if $\varphi$ and $\psi$ are both wff, so are $\varphi \wedge \psi$ \\
6. & if $\varphi$ and $\psi$ are both wff, so are $\varphi \vee \psi$ \\
\end{tabular}
\label{tab:wffs}
\end{table}

\begin{table}[!t]
\small
\centering
\caption{The Axiomatic System}
Definition of logical and modal operators (abbreviations) \\
\begin{tabular}{r l}
D1. & $\varphi \wedge \psi \equiv \neg ( \neg \varphi \vee \neg \psi)$\\
D2. & $\varphi \oplus \psi \equiv (\varphi \vee \psi) \wedge \neg(\varphi \wedge \psi)$ (exclusive or)\\
D3. & $\varphi \rightarrow \psi \equiv \neg \varphi \vee \psi $\\
D4. & $\varphi \leftrightarrow \psi \equiv (\varphi \rightarrow \psi) \wedge (\psi \rightarrow \varphi)$\\
D5. & $\Diamond \psi \equiv \exists w \in W : w \vdash \varphi $\\
D6. & $\Box \varphi \equiv \neg \Diamond \neg \varphi $\\
D7. & $B_i \varphi$ agent $i$ believes the truth of $\varphi$\\
D8. & $I_{i,j} \varphi$ agent $j$ informs $i$ that $\varphi \equiv \top$\\
D9. & $T_{i,j} \varphi$ agent $i$ trusts the report from $j$ about $\varphi$ \\
\end{tabular} \\~\\
Axioms \\
\begin{tabular}{r l}
P. & All the tautologies from the propositional calculus.\\
K. & $\Box (\varphi \rightarrow \psi) \rightarrow (\Box \varphi \rightarrow \Box \psi)$\\
M. & $\Box \varphi \rightarrow \varphi$\\
A1. & $\neg \Box \varphi \rightarrow \Box \neg \Box \varphi $\\
A2. & $\Diamond (\varphi \vee \psi) \rightarrow \Diamond \varphi \vee \Diamond \psi $\\
A3. & $\Box \varphi \wedge \Box \psi \rightarrow \Box (\varphi \wedge \psi)$ \\
B1. & $(B_i \varphi \wedge B_i (\varphi \rightarrow \psi )) \rightarrow B_i \psi$ \\
B2. & $\neg B_i \bot$\\
B3. & $B_i \varphi \rightarrow B_i B_i \varphi$ \\
B4. & $\neg B_i \varphi \rightarrow B_i \neg B_i \varphi$\\
I1. & $(I_{i,j} \varphi \wedge I_{i,j} (\varphi \rightarrow \psi )) \rightarrow I_{i,j} \psi$\\
I2. & $\neg I_{i,j} \bot$ \\
C1. & ($B_i I_{i,j} \varphi \wedge T_{i,j} \varphi) \rightarrow B_i \varphi$ \\
C2. & $T_{i,j} \varphi \equiv B_i T_{i,j} \varphi$ \\
\end{tabular} \\~\\
Rules of Inferrence \\
\begin{tabular}{r l}
R1. & From $\vdash \varphi$ and $\vdash \varphi \rightarrow \psi$ infer $\psi$ (Modus Ponens) \\
R2. & $\neg (\varphi \wedge \psi) \equiv (\neg \varphi \vee \neg \psi)$ (DeMorgan's)\\
R3. & From $\vdash \varphi$ infer $\vdash \Box \varphi$ (Generalization)\\
R4. & From $\vdash \varphi \equiv \psi$ infer $\vdash \Box \varphi \equiv \Box \psi$\\
R5. & From $\vdash \varphi \equiv \psi$ infer $\vdash T_{i,j} \varphi \equiv T_{i,j} \psi$\\
\end{tabular} \\
\label{tab:axiomatic}
\end{table}

\subsubsection{Non-Deducible (MSDND) Security}

In the domain of security there are a wide variety of aspects worth protecting in every system. These are grouped into the core security concepts of integrity, accessibility and privacy. Many traditional security approaches rely heavily on cryptography to provide privacy. However accidental information leakage can still occur, which compromises the privacy of the system. For cyber-physical systems, the leakage is difficult to control. Unlike their cyber counterparts, the actions taken by the physical components cannot be hidden from a casual observer. For example, a plane changing altitude or a car turning or changing speed cannot be hidden from an observer. Other, more complicated systems, like the power grid, have actions that are more difficult to observe, but a well motivated attacker can potentially collect critical information about the behavior of the cyber components with observations of the physical network\cite{Roth2012}.

Information Flow security models are invaluable for assessing what information, if any, is leaked by either the cyber of physical components of the \ac{CPS}. There are a number of information flow security models, all based off similar concepts. Typically, these models partition the system into two domains: the high security domain and the low security domain. However, the MSDND security model allows the system to partitioned into any number of domains. The MSDND model has been used to describe how the STUXNET attack was able to hide its malicious behavior from the operators. The MSDND security model is expressed using modal logic to determine what information in a domain is deducible to an observer in another domain. MSDND security exploits the possible worlds of modal logic to determine if there are worlds where the value of a logical atom is deducible by someone outside the domain.

This information flow security model can be used to determine what an agent in a distributed system can determine about another agent. The exact specification of timing the distributed system becomes unnecessary as the modal model can express any combination of logical atoms in one of its worlds. \cite{Howser2012}\cite{STUXNET}\cite{Howser2013}

The MSDND security model can be expressed as follows\cite{STUXNET}. Consider a pair of state variables $s_x$ and $s_y$ which may or may not be in the same security domain. The value of $s_x$ and $s_y$ have a logical xor relationship: if $s_x$ is true, $s_y$ must be false. Given an agent $i$ that does not have a valuation function for either of those two variables, the system is MSDND secure for that agent and pair of variables. Written formally:

\begin{align}
MSDND = \exists w \in W : w \vdash \Box [ (s_x \vee s_y) \wedge \neg(s_x \wedge s_y) ] 
\nonumber \\ \wedge [ w \vDash ( \not \exists V_x^i (w) \wedge \not \exists V_y^i (w) ) ]
\end{align}

Of particular interest is the special case where $s_x$ and $s_y$ are relation on the same wff: $(s_x = \varphi$ and $s_y = \neg \varphi)$:

\begin{align}
MSDND = \exists w \in W : w \vdash \Box [ \varphi \oplus \neg \varphi ] 
\nonumber \\ \wedge [ w \vDash ( \not \exists V_\varphi^i(w)) ]
\end{align}

In a system where the above logical relationship holds, the agent $i$ cannot determine the value of $s_x$ or $s_y$. However, if the relationship does not hold, there is some world where the agent can determine the value of $s_x$ and $s_y$.

\section{BIT Logic}

\ac{BIT} was developed by such and such to formalize a modal logic about belief and information transfer. \ac{BIT} logic has typically been applied to distributed systems, but also have played roles in \ac{CPS} security. The operations of the \ac{BIT} logic allow formal definition of how entities pass information, and how they will act on the information passed to them. \ac{BIT} logic utilizes several modal operators:

\begin{itemize}
\item $I_{i,j} \varphi$ defines the transfer of information directly from agent $j$ to an agent $i$. 
\item $T_{i,j} \varphi$ defines trust an agent $i$ has in a report from $j$ that $\varphi$ is true.
\item $B_i \varphi$ defines the belief that an agent $i$ has about $\varphi$. The actual value of $\varphi$ is irrelevant: the agent $i$ believes it to be true.
\end{itemize}

These operators allow reasoning about information transference between entities. In the context of a distributed system, these operators allow the division of the actual state held by some agent $i$ to what some other agent $j$ believes agent $i$'s state is.

\section{Leader Elections and Failure Detectors}

Many election algorithms have been created.
Specialized algorithms exist for wireless sensor networks\cite{LE-WSN-1}\cite{LE-WSN-2} and other special circumstances\cite{LE-SPECIALCIRCUMSTANCES-1}\cite{LE-SPECIALCIRCUMSTANCES-2}.
Work on leader elections has been incorporated into a variety of distributed frameworks: Isis\cite{ISISTOOLKIT}, Horus\cite{HORUSTOOLKIT}, Totem\cite{TOTEMTOOLKIT}, Transis\cite{TRANSISTOOLKIT}, and Spread\cite{SPREADTOOLKIT} all have methods for creating groups.
Despite this wide array of work, the fundamentals of leader election are similar.
Processes arrive at a consensus of a single peer that coordinates the group.
Processes that fail are detected and removed from the group.

The elected leader is responsible for making work assignments, identifying and merging with other coordinators when they are found, and maintaining an up-to-date list of peers.
Group members monitor the group leader by periodically checking if the group leader is still alive by sending a message.
If the leader fails to respond, the querying peers will enter a recovery state and operate alone until they can identify another coordinator.
Therefore, a leader and each of the members maintain a set of currently reachable processes, a subset of all known processes in the system.


\section{ECN}

\subsection{Random Early Detection}
The \ac{RED} queueing algorithm is a popular queueing algorithm for switches and routers.
It uses a probabilistic model and an \ac{EWMA} to determine if the average queue size exceeds predefined values.
These values are used to identify potential congestion and manage it.
This is accomplished by determining the average size of the queue, and then probabilistically dropping packets to maintain the size of the queue.
In \ac{RED}, when the average queue size $avg$ exceeds a minimum threshold ($min_{th}$), but is less than a maximum threshold ($max_{th}$), new packets arriving at the queue may be ``marked''.
The probability a packet is marked is based on the following relation between $p_{b}$ and $p_{a}$ where $p_{a}$ is the final probability a packet will be marked.

\begin{equation}
p_{b} = max_p (avg - min_{th}) / (max_{th}-min_{th})
\end{equation}
\begin{equation}
p_{a} = p_{b} / (1-count * p_b)
\end{equation}

Where $max_p$ is the maximum probability a packet will be marked when the queue size is between $min_{th}$ and $max_{th}$ and $count$ is the number of packets since the last marked packet.
With \ac{RED}, the probability a packet is marked varies linearly with the average queue size, and as a function and the time since the last packet was marked.
If $avg$ is greater than $max_{th}$, the probability of marking trends toward 1 as the average queue size approaches $2*max_{th}$
In the event the queue fills completely, the \ac{RED} queue operates as a drop-tail queue.

In a simple implementation of the \ac{RED} algorithm, marked packets are dropped.
For a TCP application, the result of the dropped packets causes the slow-start congestion control strategy to reduce the rate packets are sent.
A more advanced implementation, using \ac{ECN}, sets specific bits in the TCP header to indicate congestion.
By using \ac{ECN}, TCP connections can reduce their transmission rate without re-transmitting packets.

UDP applications have not typically utilized \ac{ECN}.
Although the \ac{ECN} standard has flags in the IPv4 header, access to the IPv4 header is not possible on most systems.
Furthermore, there is not a ``one size fits all'' solution to congestion in UDP algorithms.
However, for the \ac{DGI} and a class of similar real-time processes, congestion notification has great potential.
If processes can adjust the amount of traffic they send based on the anticipated congestion (by disabling features, for example), they can decrease the effects of congestion.

\section{Distributed Grid Intelligence}

This models the group management module of the FREEDM DGI.
The DGI is a smart grid operating system that organizes and coordinates power electronics.
It also negotiates contracts to deliver power to devices and regions that cannot effectively facilitate their own needs.
DGI leverages common distributed algorithms to control the power grid, making it an attractive target for modeling a distributed system.

The DGI software consists of a central component, known as the broker.
This broker is responsible for presenting a communication interface.
It also furnishes any common functionality the system's algorithms may need.
These algorithms, grouped into modules, work in concert to move power from areas of excess supply to excess demand.

DGI utilizes several modules to manage a distributed smart-grid system.
Group management, the focus of this work, implements a leader election algorithm to discover which processes are reachable within the cyber domain.
Other modules provide additional functionality, such as collecting global snapshots, negotiating the migrations, and giving commands to physical components.

DGI is a real-time system; certain actions (and reactions) involving power system components need to be completed within a pr-specified time-frame to keep the system stable.
It uses a round robin scheduler in which each module is given a predetermined window of execution which it may use to perform its duties.
When a module's time period expires, the next module in the line is allowed to execute. 

The DGI uses the leader election algorithm, ``Invitation Election Algorithm,'' written by Garcia-Molina\cite{INVITATIONELECTION}.
This algorithm provides a robust election procedure which allows for transient partitions.
Transient partitions are formed when a faulty link inside a group of processes causes the group to divide temporarily.
These transient partitions merge when the link becomes more reliable.

\subsection{Real Time}
The DGI's specifications also called for real time reaction to events in the system.
These real-time requirements are designed to enforce a tight upper bound on the amount of time used creating groups, discovering peers, collecting the global state, and performing migrations.

To enforce these bounds, the real-time DGI has distinct phases which modules are allowed to use for all processing.
Each module was given a phase which grants it a specific amount of processor time.
Modules used this time to complete any tasks they had prepared.
When the allotted time was up the scheduler changed context to the next module.
This interaction is illustrated in Figure \ref{fig:REALTIMESCHEDULER}

\begin{figure}[!h]
\centering
\includegraphics[width=1.0\textwidth]{RealTimeScheduler.pdf}
\captionsetup{singlelinecheck=off}
\caption[Real Time Scheduler]{The real time scheduler used a round robin approach to allot execution time to modules. 
\begin{enumerate}
    \item Modules requested that a task be executed by specifying a time in the future to execute a task.
          A timer was set to count down to the specified moment.
           Modules could place tasks immediately into the ready queue if the task could executed immediately.
    \item When the timer expires the task is placed into the ready queue.
    \item Modules were assigned periods of execution (called phases) which were a predetermined length.
          After the specified amount of time had passed, the module's phase ends and the next module in the schedule began to execute.
    \item The worker selected the next ready task for the active module from the ready queue and executed it.
          These tasks could also schedule other tasks to be run in the future.
\end{enumerate}
}
\label{fig:REALTIMESCHEDULER}
\end{figure}

Modules informed the scheduler of tasks they wish to perform.
The tasks could be scheduled for some point in the future, or scheduled to executed immediately.
When a tasks became ready was inserted into a ready queue for the module it was been scheduled for.

When that modules phase was active, tasks were pulled from the ready queue and executed.
When the phase was complete, the scheduler stopped pulling tasks from the previous module's queue and began pulling from the next module's queue.

This allowed enforcement of upper bound message delay.
Modules had a specific amount of processing time allotted.
Modules with messages that invoked responses typically required the responses to be received within the same phase.
Round numbers enforced that the message was sent within the same phase.

Modules were designed and allotted time to allow for parameters such as maximum query-response time (based on the latency between communicating processes).
This implied that a module that engaged in these activities has an upper-bound in latency before messages are considered lost.

\subsection{Group Management Algorithm}

The DGI uses the leader election algorithm, ``Invitation Election Algorithm,'' written by Garcia-Molina \cite{INVITATIONELECTION}.
Originally published in 1982, this algorithm provides a robust election  procedure that allows for transient partitions.
Transient partitions are formed when a faulty link between two or more clusters of DGIs causes the groups to divide temporarily.
These transient partitions merge when the link becomes more reliable.
The election algorithm allows for failures that disconnect two distinct sub-networks.
These sub networks are fully connected, but connectivity between the two sub-networks is limited by an unreliable link.

Since Garcia-Molina's original publication \cite{INVITATIONELECTION}, a large number of election algorithms have been created. 
Each algorithm is designed to be well-suited to the circumstances it will deployed in.
Specialized algorithms exist for wireless sensor networks \cite{LE-WSN-1}\cite{LE-WSN-2}, detecting failures in certain circumstances \cite{LE-SPECIALCIRCUMSTANCES-1}\cite{LE-SPECIALCIRCUMSTANCES-2}, and of course, transient partitions.
Work on leader elections has been incorporated into a variety of distributed frameworks: Isis \cite{ISISTOOLKIT}, Horus \cite{HORUSTOOLKIT}, Totem \cite{TOTEMTOOLKIT}, Transis \cite{TRANSISTOOLKIT}, and Spread \cite{SPREADTOOLKIT} all have methods for creating groups.
Despite this wide array of work, the fundamentals of leader election are consistent
across all work.
Processes arrive at a consensus of a single peer that coordinates the group.
Processes that fail are detected and removed from the group. 

The elected leader is responsible for making work assignments, and identifying and merging with other coordinators when they are found, as well as maintaining an up-to-date list of peers for the members of his group. 
Group members monitor the group leader by periodically checking if the group leader is still alive by sending a message. 
If the leader fails to respond, the querying nodes will enter a recovery state and operate alone until
they can identify another coordinator.
Therefore, a leader and each of the members maintain a set of processes which are currently reachable, a subset of all known processes in the system.

Leader election can also be classified as a failure detector \cite{LEADERELECTIONEVAL}.
Failure detectors are algorithms which detect the failure of processes within a system; they maintain a list of processes that they suspect have crashed.
This informal description gives the failure detector strong ties to the leader election process. 
The group management module maintains a list of suspected processes which can be determined from the set of all processes and the current membership.

The leader and the members have separate roles to play in the failure detection process.
Leaders use a periodic search to locate other leaders in order to merge groups.
This serves as a ping / response query for detecting failures within the system.
The member sends a query to its leader.
The member will only suspect the leader, and not the other processes in their group.
Of course, simple modifications could allow the member to suspect other members.
However, that modification is not implemented in DGI code.

In this work it is assumed that a leader does not span two partitioned networks; if a group was able to form, all members have some chance of communicating with one another.

Using a leader election algorithm allows the \ac{FREEDM} system to autonomously reconfigure rapidly in the event of a failure.
Cyber components are tightly coupled with the physical components, and reaction to faults is not limited to faults originating in the cyber domain.
Processes automatically react to crash-stop failures, network issues, and power system faults.
The automatic reconfiguration allows processes to react immediately to issues, faster than a human operator, without relying on a central configuration point.
However, it is important the configuration a leader election supplies is one where the system can do viable work without causing physical faults like voltage collapse or blackouts\cite{HARINI}.

A state machine for the election portion of the election algorithm is shown in Figure \ref{fig:statemachine}.
In the normal state, the election algorithm regularly searches for other coordinators to join with.
When another coordinator is identified, all other processes will yield to their future coordinator.
The method of selecting which process becomes the coordinator of the new group differentiates the modified algorithm from other approaches.

Processes determine the optimal coordinator (the one with the lowest process ID) through the exchange of \ac{AYT} and \ac{AYC} messages.
A process will only accept invites from processes more optimal than itself, and more optimal than its current leader.
Once a timeout expires, the coordinator will send a ``Ready'' message with a list of peers to all processes that accepted the invite.
To prevent live-lock the processes do not leave their previous group until the new Ready message arrives, unlike the original ``Invitation Election Algorithm.''
The invited processes have timeouts for when they expect the ready message to arrive.

Once a group is formed it must be maintained.
To do this, processes occasionally exchange messages to verify the other is still reachable.
%This interaction is shown in Figure \ref{fig:statemachine2}.
Coordinators send \ac{AYC} messages to members of its group to check if the process has left the group.
Group members send \ac{AYT} messages to the coordinator to verify they haven't been removed from the group, and to ensure the coordinator is still alive.
If processes fail to reply to received message before a timeout, they will leave the group.
Leaving the group can either be caused by the coordinator removing the process, or the process can enter a recovery state and leave the group, forming a new group by itself.

This version also removes the potential live-lock due to crash failure, although crash-failure is not considered in this work.
Other algorithms could be more efficient and less bursty during normal operation, however they are more inconsistent during network congestion and omission.

\subsection{Power Management}

In this work we utilize the load balancing algorithm from \cite{LOADBALANCING}.
The load balancing algorithm performs work by managing power devices with a sequence of migrations\cite{HILTESTBED}.
In each migration, a sequence of message exchanges identify processes whose power devices are not sufficient to meet their local demand and other processes supply them with power by utilizing a shared bus.
To do this, first processes that cannot meet their demand announce their need to all other processes.
Processes with devices that exceed their demand offer their power to processes that announced their need.
These processes perform a three-way handshake.
At the end of the handshake, the two processes have issued commands to their attached devices to supply power from the shared bus and to draw power from the shared bus.

The \ac{DGI} algorithms can tolerate packet loss and is implemented using UDP to pass messages between \ac{DGI} processes.
Effects of packet loss on the \ac{DGI}'s group management module have been explored in \cite{CRITIS2012} and \cite{JOURNAL}.
The load balancing algorithm can tolerate some message loss, but lost messages can cause migrations to only partially complete, which can cause instability in the physical network.
A failed migration is diagrammed in Figures \ref{fig:failed-migration-1} and \ref{fig:failed-migration-2}.
With this power migration algorithm, uncompensated actions may occur in the power system.
These actions can eventually lead to power instability through issues such as voltage collapse.
Additionally, the supply process may not always be certain if the second half of the action was completed or not.
If the ``Draft Accept'' message does not arrive from the demand process, the supply process cannot be certain of whether or not its ``Draft Select'' message was received.
If the supply process takes action to compensate by reversing the migration and the confirmation arrives later the system will also be driven towards instability because another process completed an uncompensated action.
Processes could potentially confirm the number of failed migrations with a state collection technique.
It is therefore desirable to manage the processes to minimize the number failed migrations.
In this work, we consider effects due to delays by congestion.

\begin{figure}
\centering
\includegraphics[width=0.95\textwidth]{FailedMigration1}
\caption{Example of a failed migration. (*) and (**) mark moments when power devices change state to complete the physical component of the migration. In this scenario, the message confirming the demand side made the physical is lost, leaving the supply node uncertain.}
\label{fig:failed-migration-1}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.95\textwidth]{FailedMigration2}
\caption{Example of a failed migration. (*) marks a moment when power devices change state to complete the physical component of the migration. In this scenario, the supply process changes its device state, but the demand process does not.}
\label{fig:failed-migration-2}
\end{figure}

A real-time system implementing this algorithm could count the number of failed migrations with a counter.
The counter will increase when the physical side makes a change, increasing the number of outstanding migrations.
The demand process will make their physical change and send the ``Draft Accept'' message.
On receipt, the counter is reduced by one.
A real-time deadline is enforced on the receipt of the ``Draft Accept'' -- if the message does not arrive before a specific time interval, the counter will not be decreased.

